---
title             : "The emergence of words from vocal imitations"
shorttitle        : "Words from imitations"

author:
  - name          : "Pierce Edmiston"
    affiliation   : "1"
    corresponding : yes
    address       : "1202 W. Johnson St., Madison, WI, 53703"
    email         : "pedmiston@wisc.edu"
  - name          : "Marcus Perlman"
    affiliation   : "2"
  - name          : "Gary Lupyan"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Wisconsin-Madison"
  - id            : "2"
    institution   : "University of Birmingham"

author_note: >
  Pierce Edmiston and Gary Lupyan, Department of Psychology, University of
  Wisconsin-Madison, Madison, Wisconsin. Marcus Perlman, Department of English
  Language and Applied Linguistics, University of Birmingham, United Kingdom.
abstract: >
  People have long pondered the origins of language, especially the words that
  compose them. Here, we report a series of experiments investigating how
  conventional spoken words might emerge from imitations of environmental
  sounds. Does the repeated imitation of an environmental sound gradually give
  rise to more word-like forms? In what ways do these words resemble the original
  sounds that motivated them (i.e., iconicity)? Participants played a version of
  the children’s game “Telephone”. The first generation of participants imitated
  recognizable environmental sounds (e.g., glass breaking, water splashing).
  Subsequent generations imitated the previous generation of imitations for a
  maximum of 8 generations. The results showed that the imitations became more
  stable and word-like, and later imitations were easier to learn as category
  labels. At the same time, even after 8 generations, both spoken imitations and
  their written transcriptions could be matched above chance to the category of
  environmental sound that motivated them. These results show how repeated
  imitation can create progressively more word-like forms while continuing to
  retain a resemblance to the original sound that motivated them, and speak to
  the possible role of human vocal imitation in explaining the origins of at
  least some spoken words.
keywords          : "language evolution, iconicity, vocal imitation, transmission chain"
wordcount         : "X"

bibliography      : ["references.bib"]

figsintext        : yes
figurelist        : yes
tablelist         : yes
footnotelist      : yes
lineno            : yes

lang              : "english"
class             : "man"
output            :
  papaja::apa6_pdf:
    keep_tex: yes
---

```{r config, include=FALSE}
library(knitr)

opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  results="hide",
  cache=TRUE,
  fig.width=4,
  fig.height=4
)

sapply(list.files("R", "*.R", full.names = TRUE), read_chunk)
```

```{r setup, include=FALSE, cache=FALSE}
```

Most vocal communication of non-human primate species is based on
species-typical calls that are highly similar across generations and between
populations [e.g. @Seyfarth:1986tw] [but see, e.g. @Crockford:2004cz]. In
contrast, human languages comprise a vast repertoire of learned meaningful
elements (words and other morphemes) which can number in the tens of thousands
or more [e.g., @Brysbaert:2016fg]. Aside from their number, the words of
different natural languages are characterized by their extreme diversity
[@Wierzbicka:1996sm; @Evans:2009dk; @Lupyan:2016uw]. The words used within a
speech community change relatively quickly over generations compared to the
evolution of vocal signals [e.g., @Pagel:2007br]. At least in part as a
consequence of this divergence, most words appear to bear a largely arbitrary
relationship between their form and their meaning --- seemingly, a product of
their idiosyncratic etymological histories [@Sapir:1921; @Labov:1972]. The
apparently arbitrary nature of spoken vocabularies presents a quandary for the
study of language origins. If words of spoken languages are truly arbitrary, by
what process were the first words ever coined?

While the origin of most spoken words is hard to discern, the situation is
somewhat different for signed languages. In signed languages, the origins of
many signs are relatively transparent. Although signed languages rely on the
same type of referential symbolism as spoken languages, many individual signs
have clear iconic roots, formed from gestures that resemble their meaning
[@Frishberg:1975dh; @GoldinMeadow:2016bw; @Kendon:2014eg; @Klima:1980si]. For
instance, @Frishberg:1975dh noted the iconic origins of the American Sign
Language (ASL) sign for bird, which is formed with a beak-like handshape
articulated in front of the nose. Another example is steal, derived from a
grabbing motion to represent the act of stealing something. @Stokoe:1965
identified about 25% of American Sign Language signs to be iconic, and reviewing
the remaining 75% of ASL signs, @Wescott:1971to determined that about two-thirds
of these seemed plausibly derived from iconic origins. Further support for
iconic origins of signed languages comes from observations of deaf children
raised without exposure to a signed language, who develop homesign systems to
use with their family. These communication systems are generally built from a
process in which the children establish conventional gestures through the use of
pantomimes and various iconic and indexical gestures [e.g. @GoldinMeadow:1977gz].
Participants in laboratory experiments utilize a similar strategy when they
communicate with gestures in iterated communication games [@Fay:2014cw].

In contrast to the visual gestures of signed languages, many have argued that
iconic vocalizations could not have played a significant role in the origin of
spoken words because the vocal modality simply does not afford much resemblance
between form and meaning [@Arbib:2012htb; @Armstrong:2007go; @Corballis:2003ha;
@Hewes:1973vr; @Hockett:1978se; @Tomasello:2010or]. It has also been argued that
the human capacity for vocal imitation is a domain-specific skill, geared
towards learning to speak, rather than the representation of
environmental sounds. For example, @Pinker:2005cv suggested that, “most humans
lack the ability… to convincingly reproduce environmental sounds… Thus ‘capacity
for vocal imitation’ in humans might be better described as a capacity to learn
to produce speech” (p. 209). Consequently, it is still widely assumed that vocal
imitation --- or more broadly, the use of any sort of resemblance between form
and meaning --- cannot be important to understanding the origin of spoken words.

Although most words of contemporary spoken languages are not clearly imitative
in origin, there has been a growing recognition of the importance of iconicity
in spoken languages [@Dingemanse:2015cu; @Perniss:2010fb] and the common use of
vocal imitation and depiction in spoken discourse [@Clark:1990cl; @Lewis:2009wz].
This has led some to argue for the importance of imitation for understanding the
origin of spoken words [e.g., @Brown:1955wy; @Dingemanse:2014gj; @Donald:2016kd;
@Imai:2014dea; @Perlman:2015ip]. In addition, counter to previous assumptions,
people are highly effective at using vocal imitations to refer to environmental
sounds such as coins dropping in a jar or mechanical events such as scraping ---
in some cases, even more effective than when using conventional words
[@Lemaitre:2014kr]. Recent work has also shown that people are able to create
novel imitative vocalizations for more abstract meanings (e.g. ‘slow’, ‘rough’,
‘good’, ‘many’) that are understandable to naïve listeners [@Perlman:2015ip].
These imitations are effective not because people can mimic environmental sounds
with high fidelity, but because people are able to produce imitations that
capture the salient features of sounds in ways that are understandable to
listeners [@Lemaitre:2016kz]. Similarly, the features of onomatopoeic words
might highlight distinctive aspects of the sounds they represent. For example,
the initial voiced, plosive /b/ in “boom” represents an abrupt, loud onset, the
back vowel /u/ a low pitch, and the nasalized /m/ a slow, muffled decay
[@Rhodes:1994au].

Thus, converging evidence suggests that people can use vocal imitation as an
effective means of communication. At the same time, vocal imitations are not
words. If vocal imitation played a role in the origin of some spoken words, then
it is necessary to identify the minimal conditions under which vocal imitations
can give rise to more word-like vocalizations that can eventually be integrated
into a vocabulary of a language. In the present set of studies we ask whether
vocal imitations can transition to more word-like forms through sheer repetition
--- without an explicit intent to communicate. To answer this question, we
recruited participants to play an online version of the children's game of
"Telephone". In the children’s game, a spoken message is whispered from one
person to the next. In our version, the original message or "seed sound" was a
recording of an environmental sound. The initial group of participants (first
generation) imitated these seed sounds, the next generation imitated the
previous imitators, and so on for up to 8 generations.

Our approach uses a transmission chain methodology similar to that frequently
used in experimental studies of language evolution [@Tamariz:2017bd, for
review]. As with other transmission chain studies (and iterated learning studies
more generally), we seek to discover how various biases and constraints of
individuals change the nature of a linguistic signal. Importantly, while typical
transmission chain studies focus on the impact of learning biases [e.g.,
@Kirby:2008kja], the present studies involve iterated reproduction that does not
involve any learning. Participants simply attempt to imitate a sound as best as
they can. The biases we hypothesize to drive vocalizations to become more
word-like are therefore not related to any learning process, but instead are
expected to emerge from constraints on the reproducibility of vocalizations. Our
aim is thus to determine whether iterated reproduction, even without learning,
is a sufficient enough constraint to enable the emergence of more word-like
signals.

After collecting the imitations, we conducted a series of analyses and
additional experiments to systematically answer the following questions: First,
do imitations stabilize in form and become more word-like as they are repeated?
Second, do the imitations retain a resemblance to the original environmental
sound that inspired them? If so, it should be possible for naïve participants to
match the emergent words back to the original seed sounds. Third, do the
imitations become more suitable as categorical labels for the sounds that
motivated them? For example, does the imitation of a particular water-splashing
sound become, over generations of repeated imitation, a better label for the
more general category of water-splashing sounds?

# Experiment 1: Stabilization of imitations through repetition

```{r stability, include=FALSE}
```

In the first experiment, we collected the vocal imitations, and assessed the
extent to which repeating imitations of environmental sounds over generations of
unique speakers results in progressive stabilization toward more word-like
forms. After collecting the imitations, we measured changes in the stability of
the imitations in three ways. First, we measured changes in the perception of
acoustic similarity between subsequent generations of imitations. Second, we
used algorithmic measures of acoustic similarity to assess the similarity of
imitations sampled within and between transmission chains. Third, we obtained
transcriptions of imitations, and measured the extent to which later generation
imitations were transcribed with greater consistency and agreement. The results
show that repeated imitation results in vocalizations that are easier to repeat
with high fidelity and more consistently transcribed into English orthography.

## Methods

### Selecting seed sounds

To avoid sounds with lexicalized or conventionalized onomatopoeic forms in
English, we used inanimate categories of environmental sounds. To select sounds
that were equally distinguishable within each category, we used an odd-one-out
norming procedure (_N_=`r n_norming_subjects` participants; see Fig. S1),
resulting a final set of 16 sounds in each of 4 categories. The four categories
were: glass, tear, water, zipper.

### Collecting vocal imitations

Participants (_N_=`r n_imitators`) recruited from Amazon Mechanical Turk were
paid to participate in an online version of the children's game of "Telephone".
Participants were instructed that they would hear some sound and their task was
to reproduce it as accurately as possible using their computer microphone. Full
instructions are provided in the Supplemental Materials.

Each participant listened to and imitated four sounds: one from each of the four
categories of environmental sounds. Sounds were assigned at random such that
participants were unlikely to imitate the same person more than once.
Participants were allowed to listen to each target sound as many times as they
wished, but were only allowed a single recording in response. Recordings that
were too quiet (less than -30 dBFS) were not accepted.

Imitations were monitored by an experimenter to remove background sounds
and trim the imitations to the length of the utterance. The experimenter
also removed recordings that violated the rules of the experiment, e.g., an
utterance in English. A total of `r n_removed` (`r n_removed_pct`%)
imitations were removed prior to subsequent analysis. The final sample contained
`r n_final_imitations` imitations along `r n_branches` contiguous transmission
chains (Fig. 1).

```{r fig1, fig.width=4, fig.height=3.5, fig.cap="Vocal imitations collected in the transmission chain experiment. Seed sounds (16) were sampled from four categories of environmental sounds: glass, tear, water, zipper. Participants imitated each seed sound, and then the next generation of participants imitated the imitations, and so on, for up to 8 generations. Chains are unbalanced due to random assignment and the exclusion of some low quality recordings."}
gg_dendrogram
```

### Measuring acoustic similarity

Acoustic similarity judgments were obtained from five research assistants who
listened to pairs of sounds (approx. 300) and rated their subjective similarity.
On each trial, raters heard two sounds from subsequent generations played in
random order. They then indicated the similarity between the sounds on a 7-
point Likert scale from _Entirely different and would never be confused_ to
_Nearly identical_. Full instructions and inter-rater reliability measures are
provided in the Supplemental Materials. Ratings were normalized for each rater
(z-scored) prior to analysis.

To obtain algorithmic measures of acoustic similarity, we used the acoustic
distance functions included in Phonological Corpus Tools [@PCT:1.1]. We computed
Mel-frequency cepstral coefficients (MFCCs) between pairs of imitations using 12
coefficients in order to obtain speaker-independent estimates.

### Collecting transcriptions of imitations

Participants (_N_=`r n_transcribers`) recruited from Amazon Mechanical Turk
were paid to listen to the imitations and write down what they heard as a
single "word" so that the written word would sound as much like the sound as
possible. Participants were instructed to avoid transcribing the imitations
into existing English words. Each participant completed 10 transcriptions.

Transcriptions were gathered for the first and the last three generations of
imitations. Additional "transcriptions" directly of the original environmental
seed sounds are analyzed in the Supplementary Materials (Fig. S6).

### Analyses

Statistical analyses were conducted in R using linear mixed-effects
models provided by the `lme4` package [@lme4:2015]. Degrees of freedom and
corresponding significance tests for linear mixed-effects models were estimated
using the Satterthwaite approximation via the `lmerTest` package 
[@lmerTest:2016]. Random effects (intercepts and slopes) for subjects and for items were
included wherever appropriate, as described below.

## Results

Imitations of environmental sounds became more stable over the course of
being repeated as revealed by increasing acoustic similarity judgments along
individual transmission chains. Acoustic similarity ratings were fit with
a linear mixed-effects model predicting perceived acoustic similarity from
generation with random effects (intercepts and slopes) for raters. To test
whether the hypothesized increase in acoustic similarity was true across all
seed sounds and categories, we added random effects (intercepts and slopes)
for seed sounds nested within categories. The results showed that, across
raters and seeds, imitations from later generations were rated as sounding
more similar to one another than imitations from earlier generations,
`r lmer_mod_results(similarity_judgments_lmertest_mod, "edge_generation_n")`
(Fig. 2). This result suggests that imitations became more stable (i.e., easier
to imitate with high fidelity) with each generation of repetition.

```{r fig2, fig.cap="Change in perception of acoustic similarity over generations of iterated imitation. Points depict mean acoustic similarity ratings for pairs of imitations in each category. The predictions of the linear mixed-effects model are shown with ±1 SE."}
gg_similarity_judgments
```

Increasing similarity along transmission chains could also reflect the
continuous degradation of the signal due to repeated imitation, in which case
acoustic similarity would increase both within as well as between chains. To
test this, we calculated MFCCs for pairs of sounds sampled from within and
between transmission chains across categories, and fit a linear model predicting
acoustic similarity from the generation of sounds. We found that acoustic
similarity increased within chains more than it increased between chains,
`r lm_mod_results(algo_similarity_mod, "edge_generation_n:type_c")` (Fig. S2),
indicating that imitations were stabilizing on divergent acoustic
forms as opposed to converging on similar forms through continuous degradation.

An additional test of stabilization and word-likeness was to measure
whether later generation imitations were transcribed more consistently than
first generation imitations. We collected a total of `r n_transcriptions`
transcriptions --- approximately `r n_transcriptions_per_imitation`
transcriptions per sound. Of these, `r n_english_transcriptions` transcriptions
(8%) were removed because they contained English words. Some examples of the
final transcriptions are presented in Table 1.

```{r table1, results='asis'}
table_caption <- "Examples of words transcribed from imitations."
kable(transcription_examples_small, caption = table_caption)
```

To measure the similarity among transcriptions, we calculated the orthographic
distance between the most frequent transcription and all other transcriptions
of a given imitation. The orthographic distance measure was a ratio based on
longest contiguous matching subsequences between two transcriptions. We
then fit a hierarchical linear model predicting orthographic distance from the
generation of the imitation (First generation, Last generation) with random
effects (intercepts and slopes) for seed sound nested within category[^df].
The results showed that transcriptions of last generation imitations were more
similar to one another than transcriptions of first generation imitations,
`r lmer_mod_results(orthographic_distance_lmertest_mod, "message_c")` (Fig.
S3). The same result is reached through alternative measures of orthographic
distance, such as the percentage of exact transcription matches for each
imitation, `r lm_mod_results(exact_string_matches_mod, "message_c")`,
and the length of the longest matching substring,
`r lmer_mod_results(substr_length_mod, "message_c")` (Fig. S4). Differences
between transcriptions of human vocalizations and transcriptions directly of
environmental sound cues are reported in the Supplementary Materials (Fig. S6).

[^df]: Random effects for subject were not appropriate because the distance measure was derived from pairwise comparisons of transcriptions generated by different transcribers. As a result, the degrees of freedom for the significance tests for the parameters of this model reflect the Satterthwaite approximation based on the number of seed sounds (16) nested within categories (4), not the number of unique transcribers (_N_=`r n_transcribers`).

## Discussion

Repeating imitations of environmental sounds over generations of unique speakers
was sufficient to create more word-like forms, even without any explicit
intent to communicate. We defined word-likeness in terms of acoustic stability
and orthographic agreement. With each repetition, the acoustic forms of the
imitations became more similar to one another, indicating they became easier
to repeat with high fidelity. The possibility that this similarity was due to
uniform degradation across all transmission chains was ruled out by algorithmic
analyses of acoustic similarity demonstrating that acoustic similarity increased
within chains but not between them. Additionally, later generation imitations
were transcribed more consistently into English orthography, further supporting
our hypothesis that repeating imitations makes them more word-like.

The results of Experiment 1 demonstrate the ease with which iterated imitation
gives rise to new word forms. However, the results do not address how these
emergent words relate to the original sounds that were being imitated. As the
imitations became more word-like, were they stabilizing on arbitrary acoustic
and orthographic forms, or did they maintain some resemblance to the
environmental sounds that motivated them? The purpose of Experiment 2 was to
assess the extent to which repeated imitations and their transcriptions
maintained a resemblance to the original set of seed sounds.

# Experiment 2: Resemblance of imitations to original seed sounds

```{r matching, include=FALSE}
```

To assess the resemblance of repeated imitations to the original seed sounds,
we measured the ability of participants naïve to the design of the experiment
to match imitations and their transcriptions back to their original sound
source relative to other seed sounds from either the same category or from
different categories (Fig. 4). Using these match accuracies, we first asked
whether and for how many generations the imitations and their transcriptions
could be matched back to the original sounds. Second, we asked whether repeated
imitation resulted in a uniform degradation of the signal in each imitation,
or if repeated imitation resulted in some kinds of information degrading more
rapidly than others. Specifically, we tested the hypothesis that if imitations
were becoming more word-like, then they should also be interpreted more
categorically, and thus we anticipated that imitations would lose information
identifying the specific source of an imitation more rapidly than category
information that identifies the category of environmental sound being imitated.

```{r fig4, fig.width=4, fig.height=3.5, fig.cap="Three types of matching questions. Participants were presented an imitation or its transcription and selected one of four seed sounds. True seed and category match questions had choices from different sound categories. Specific match questions pitted the actual seed against the other seeds within the same category."}
grid.arrange(
  read_graphviz("true-seed", "wordsintransition"),
  read_graphviz("category-match", "wordsintransition"),
  read_graphviz("specific-match", "wordsintransition"),
  ncol = 1
)
```

## Methods

### Matching imitations to seed sounds

Participants (_N_=`r n_all_matching_imitations`) recruited from Amazon
Mechanical Turk were paid to listen to imitations, one at a time, and for each
one, choose one of four possible sounds they thought the person was trying to
imitate. The task was not speeded and no feedback was provided. Participants
completed 10 questions at a time.

All imitations were tested in each of the three question types depicted in Fig.
4. These questions differed in the relationship between the imitation and the
four seed sounds provided as the choices in the question. Question types (True
seed, Category match, Specific match) were assigned between-subject.

### Matching transcriptions to seed sounds

Participants (_N_=`r n_all_transcription_match_subjs`) recruited from Amazon
Mechanical Turk completed a modified version of the matching survey described
above. Instead of listening to imitations, participants now read a word (a
transcription of an imitation), which they were told was invented to describe
one of the four presented sounds. The distractors for all questions were
between-category, i.e. true seed and category match. Specific match questions
were omitted.

Of the unique transcriptions that were generated for each sound (imitations
and seed sounds), only the top four most frequent transcriptions were
used in the matching experiment. Participants who failed a catch trial
(_N_=`r n_transcription_match_subjs_failed_catch_trial`) were excluded, leaving
`r n_transcription_match_subjs` participants in the final sample.

## Results

Response accuracies in matching imitations to seed sounds were fit by a
generalized linear mixed-effects model predicting match accuracy as different
from chance (25%) based on the type of question being answered (True seed,
Category match, Specific match) and the generation of the imitation. Question
types were contrast coded using Category match questions as the baseline
condition in comparison to the other two question types, each containing the
actual seed that generated the imitation as one of the choices. The model
included random intercepts for participant[^generations], and random slopes and
intercepts for seed sounds nested within categories.

[^generations]: Random slopes for generation were not appropriate in the by-subject random effects because data collection was batched by generation of imitation, and therefore each participant did not sample across the range of generations.

Accuracy in matching first generation imitations to
seed sounds was above chance for all question types,
`r glmer_mod_results(imitation_matches_overall_mod, "(Intercept)", odds = TRUE)`,
and decreased steadily over generations,
`r glmer_mod_results(imitation_matches_overall_mod, "generation_1")`.
We then tested whether this increase in difficulty was constant across
the three types of questions or if some question types became more
difficult than others. The results are shown in Fig. 5A. Performance
decreased over generations more rapidly for questions requiring a
within-category distinction than for between-category questions,
`r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_within")`,
suggesting that between-category information was more resistant to loss through
repeated imitation.

An alternative explanation of the drop off in accuracy for within-category
questions but not category match questions is that the within-category
questions are simply more difficult because the sounds presented as choices
are more acoustically similar to one another. However, performance also
decreased relative to the category match questions for the easiest type
of question where the correct answer was the actual seed generating the
imitation (True seed questions; see Fig. 4). That is, the advantage of having the
true seed among between-category distractors decreased over generations,
`r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_between")`.
The observed decrease in the "true seed advantage" (the advantage of having
the actual seed among the choices) combined with the increase in the "category
advantage" (the advantage of having between-category distractors) shows
that the changes induced by repeated imitation caused the imitations to lose
some of properties that linked the earlier imitations to the specific sound that
motivated them, while nevertheless preserving a more abstract category-based
resemblance.

We next report the results of matching the written transcriptions of the
auditory sounds back to the original environmental sounds. Remarkably,
participants were able to guess the correct meaning of a word that was
transcribed from an imitation that had been repeated up to 8 times,
`r glmer_mod_results(transcription_matches_last_gen_mod, "(Intercept)", odds = TRUE)`
(Fig. 5B). This was true for True seed questions containing
the actual seed generating the transcribed imitation,
`r glmer_mod_results(transcription_matches_last_gen_mod_category, "(Intercept)")`,
and for Category match questions where participants had to associate
transcriptions with a particular category of environmental sounds,
`r glmer_mod_results(transcription_matches_last_gen_mod_exact, "(Intercept)")`.
The effect of generation did not vary across these question types,
`r glmer_mod_results(acc_mod, "question_c:message_c")`. The results of matching
"transcriptions" directly of the environmental sounds are shown in Fig. S6.

```{r fig5, fig.width=6, fig.height=3.5, fig.cap='Repeated imitations retained category resemblance. A. Accuracy in matching vocal imitations to original seed sounds. Curves show predictions of the generalized linear mixed effects models with ±1 SE of the model predictions. B. Accuracy in matching transcriptions of the imitations to original seed sounds (e.g., "boococucuwich" to a water splashing sound). Circles show mean matching accuracy for the vocal imitations that were transcribed for comparison.'}
grid.arrange(
  gg_match_to_seed +
    ggtitle("A"),
  gg_match_transcriptions +
    ggtitle("B") +
    theme(axis.title.y = element_blank()),
  nrow = 1,
  widths = c(0.6, 0.4)
)
```

## Discussion

Even after being repeated up to 8 times across 8 different individuals,
vocalizations retained a resemblance to the environmental sound that motivated
them. This resemblance remained even after the vocalizations were transcribed
into orthographic forms. For vocal imitations, but not for transcriptions this
resemblance was stronger for the category of environmental sound than the actual
seed sound, suggesting that through repetition, the imitations were becoming
more categorical. This result highlights another aspect of word-likeness
achieved through repeated imitation: In addition to being stable in acoustic and
orthographic forms, iterated imitation produces vocalizations that are
interpreted by naïve listeners in a more categorical way. Iterated
imitation appears to strip the vocalizations of some of the characteristics that
individuate each particular sound while maintaining some category-based
resemblance (even though participants were never informed about the meaning of
the vocalizations and were not trying to communicate).

Transcriptions of the vocalizations, like the vocalizations themselves, were
able to be matched to the original environmental sounds at levels above chance.
Unlike vocalizations, the transcriptions continued to be matched
more accurately to the true seed compared to the general category. That is,
transcription appears to impact specific and category-level information equally.
One possible explanation of the difference between the acoustic and
orthographic forms of this task is that the process of transcribing a non-
linguistic vocalization into a written word encourages transcribers to
emphasize individuating information about the vocalization. However, the
fact that transcriptions of imitations can be matched back to other category
members (Category match questions) suggests that transcriptions still carry
some category information, so this is not a complete explanation of our
results. Another possible reason is that by selecting only the most frequent
transcriptions, we unintentionally excluded less frequent transcriptions that
were nonetheless more diagnostic of category information.

Experiments 1 and 2 document a process of gradual change from an imitation of an
environmental sound to a more word-like form. But do these emergent words
function like other words in the language? In Experiment 3, we test the
suitability of words taken from the beginning and end of transmission chains in
serving as category labels in a category learning task.

# Experiment 3: Suitability of created words as category labels

```{r learning, include=FALSE}
```

One consequence of imitations becoming more word-like is that they may make
for better category labels. For example, an imitation from a later generation,
by virtue of having a more word-like form, may be easier to learn as a label
for the category of sounds that motivated it than an earlier imitation, which
is more closely yoked to a particular environmental sound. To the extent
that repeating imitations abstracts away the idiosyncrasies of a particular
category member [@Edmiston:2015he; @Lupyan:2012cp], it may also be easier to
generalize to new category members. We tested these predictions using a category
learning task in which participants learned novel labels for the categories of
environmental sounds. The novel labels were transcriptions of either first or
last generation imitations gathered in Experiment 1.

## Methods

### Selecting words to learn as category labels

Of the `r n_created_words` unique words created through the transmission chain
and transcription procedures, we sampled `r n_lsn_words` words transcribed
from first and last generation imitations that were equated in terms of
length and match accuracy with the original sounds. Our procedure for sampling
transcriptions is detailed in the Supplementary Materials.

### Procedure

Participants (_N_=`r n_all_lsn_subjs`) were University of Wisconsin
undergraduates who received course credit for participation. Participants
were randomly assigned four novel labels to learn for four categories of
environmental sounds. Full instructions are provided in the Supplementary
Materials. Participants were assigned between-subject to learn labels
(transcriptions) of either first or last generation imitations. Some
participants learned labels from transcriptions of seed sounds (Fig. S6). On
each trial, participants heard one of the 16 seed sounds. After a 1s delay,
participants saw a label (one of the transcribed imitations) and responded yes
or no using a gamepad controller depending on whether the sound and the word
went together. Participants received accuracy feedback (a bell sound and a green
checkmark if correct; a buzzing sound and a red "X" if incorrect). Four outlier
participants were excluded from the final sample due to high error rates and
slow RTs.

Participants categorized all 16 seed sounds over the course of the experiment,
but they learned them in blocks of 4 sounds at a time. Within each block of 24
trials, participants heard the same four sounds and the same four words multiple
times, with a 50% probability of the sound matching the word on any given trial.
At the start of a new block of trials, participants heard four new sounds they
had not heard before, and had to learn to associate these new sounds with the
words they had learned in the previous blocks.

## Results

Participants began by learning through trial-and-error to associate four
written labels with four categories of environmental sounds. The small
number of categories made this an easy task (mean accuracy after the first
block of 24 trials was 81%; Fig. S5). Participants learning transcriptions
of first or last generation imitations did not differ in overall accuracy,
`r glmer_mod_results(lsn_first_block_error_mod, "message_c", p_value_only = TRUE)`,
or reaction time,
`r lmer_mod_results(lsn_first_block_rt_mod, "message_c", p_value_only = TRUE)`.

After this initial learning phase (i.e. after the first block of trials),
accuracy performance quickly reached ceiling and did not differ between groups
`r glmer_mod_results(lsn_after_first_block_error_mod, "message_c", p_value_only = TRUE)`.
However, the response times of participants learning last
generation transcriptions declined more rapidly with practice
than participants learning first generation transcriptions,
`r lmer_mod_results(lsn_after_first_block_lmertest_mod, "message_c")` (Fig. 6A).
These faster responses suggest that, in addition to becoming more stable both in
terms of acoustic and orthographic properties, repeating imitations makes them
easier to process as category labels. We predict that given a harder task (i.e.,
more than four categories and 16 exemplars) would yield differences in initial
learning rates as well.

Next, we examined whether transcriptions from last generation imitations
were easier to generalize to novel category exemplars. To test this
hypothesis, we compared RTs on trials immediately prior to the introduction
of novel sounds (new category members) and the first trials after the block
transition (±6 trials). The results revealed a reliable interaction between
the generation of the transcribed imitation and the block transition,
`r lmer_mod_results(transition_lmertest_mod, "block_transition_c:message_c")`
(Fig. 6B). This result suggests that transcriptions from later generation
imitations were easier to generalize to new category members.

```{r fig6, fig.width=6, fig.height=3.5, fig.cap="Repeated imitations made for better category labels. A. Mean RTs for correct responses in the category learning experiment with ±1 SE. B. Cost of generalizing to new category members with ±1 SE."}
grid.arrange(
  rt_plot +
    ggtitle("A"),
  gg_transition +
    theme(axis.title.y = element_blank()) +
    ggtitle("B"),
  nrow = 1,
  widths = c(0.55, 0.45)
)
```

## Discussion

The results of a simple category learning experiment demonstrate a possible
benefit to the stabilization of repeated imitations on more word-like forms.
As a consequence of being more word-like, repeated imitations were responded
to more quickly, and generalized to new category members more easily. These
results suggest an advantage to repeating imitations from the perspective of the
language learner in that they afford better category generalization.

# General Discussion

Accumulating evidence shows that iconic words are prevalent across the spoken
languages of the world [@Dingemanse:2015cu; @Imai:2014dea; @Perniss:2010fb]. And
counter to past assumptions about the limitations of human vocal imitation,
people are surprisingly effective at using vocal imitation to represent and
communicate about the sounds in their environment [@Lemaitre:2016kz] and more
abstract meanings [@Perlman:2015ip]. These findings raise the hypothesis that
early spoken words originated from vocal imitations, perhaps comparable to the
way that many of the signs of signed languages appear to be formed originally
from pantomimes [@Fay:2014ih; @Perlman:2015ip]. Here, we examined whether simply
repeating an imitation of an environmental sound---with no intention to create a
new word or even to communicate---produces more word-like forms.

Our results show that through unguided repetition, imitative vocalizations
became more word-like both in form and function. In form, the vocalizations
gradually stabilized over generations, becoming more similar from imitation to
imitation. The standardization was also found when the words were transcribed
into the English alphabet. Even as the vocalizations became more word-like, they
maintained a resemblance to the original environmental sounds that motivated
them. Notably, this resemblance appeared to be greater with respect to the
category of sound (e.g., water-splashing sounds), rather than to the specific
exemplar (a particular water-splashing sound). After eight generations the
vocalizations could no longer be matched to the particular sound from which they
originated any more accurately than they could be matched to the general
category of environmental sound. Thus, information that distinguished an
imitation from other sound categories was more resilient to transmission decay
than exemplar information within a category. Remarkably, the resemblance to the
original sounds was maintained even when the vocalizations were transcribed into
a written form: participants were able to match the transcribed vocalizations to
the original sound category at levels above chance.

We further tested the hypothesis that repeated imitation led to vocalizations
becoming more word-like by testing the ease with which people learned the
(transcribed) vocalizations as category labels (e.g., “pshfft” from generation 1
vs. “shewp” from generation 8 as labels for tearing sounds) (Exp. 3). Labels
from the last generation were responded to more quickly than labels from the first
generation. More importantly the labels from the last generation generalized
better to novel category members. This fits with previous research showing that
the relatively arbitrary forms that are typical of words (e.g. “dog”) makes them
better suited to function as category labels compared to direct auditory cues
(e.g., the sound of a dog bark) [@Lupyan:2012cp; @Edmiston:2015he;
@Boutonnet:2015fz].

Even as the vocalizations became more word-like, they nevertheless maintained an
imitative quality. After eight generations they could no longer be matched to
the particular sound from which they originated any more accurately than they
could be matched to the general category of environmental sound. Thus,
information that distinguished an imitation from other sound categories was more
resilient to transmission decay than exemplar information within a category.
Remarkably, even after the vocalizations were transcribed into English
orthography, participants were able to guess their original sound category from
the written "words". In contrast to the vocalizations, participants continued to
be more accurate at matching late generation transcriptions back to their
particular source sound relative to other exemplars from the same category.

Unlike the large number of iconic signs in signed languages [e.g.
@GoldinMeadow:2016bw], the number of iconic words in spoken languages may appear
to be very small [@Crystal:1987en; @Newmeyer:1992we]. However, increasing
evidence from disparate language suggests that vocal imitation is, in fact, a
widespread source of vocabulary. Cross-linguistic surveys indicate that
onomatopoeia—iconic words used to represent sounds—are a universal lexical
category found across the world’s languages [@Dingemanse:2012fc]. Even English,
a language that has been characterized as relatively limited in iconic
vocabulary [@Vigliocco:2014fc], is documented as having hundreds of onomatopoeic
words not only for animal and human vocalizations (“meow”, “tweet”, “slurp”,
“babble”, murmur”), but also for a variety of environmental sounds (e.g.,
“ping”, “click”, “plop”) [e.g., @Rhodes:1994au; @Sobkowiak:1990ph]. Besides
words that directly resemble sounds --- the focus of the present study --- many
languages contain semantically broader inventories of ideophones. These words
comprise a grammatically and phonologically distinct class of words that are
used to express various sensory-rich meanings, such as qualities related to
manner of motion, visual properties, textures and touch, inner feelings and
cognitive states [@Dingemanse:2012fc; @Nuckolls:1999ca; @Voeltz:2001vv]. As with
onomatopoeia, ideophones are often recognized by naïve listeners as bearing a
degree of resemblance to their meaning [@Dingemanse:2016vd].

Our study focused on imitations of environmental sounds, and more work remains
to be done to determine the extent to which vocal imitation can ground de novo
vocabulary creation in other semantic domains [e.g., @Lupyan:2015vic;
@Perlman:2015ip]. Notably, our hypothesis that vocal imitation may have played a
role in the origin of some of the first spoken words does not preclude that
gesture played an equal or more important role in establishing the first
linguistic conventions [e.g. @Fay:2013jpa; @GoldinMeadow:2016bw;
@Kendon:2014eg]. What the present results make clear is that the transition from
imitation to word can be a rapid and simple process: the mere act of repeated
imitation can drive vocalizations to become more word-like in both form and
function while still retaining some resemblance to the real world referents.

# Ethics

This was approved by the University of Wisconsin-Madison's Educational
and Social/Behavioral Sciences Institutional Review Board and conducted in
accordance with the principles expressed in the Declaration of Helsinki.
Informed consent was obtained for all participants.

# Data, code, and materials

Our data along with all methods, materials, and analysis scripts, are available
in public repositories described on the Open Science Framework page for this
research here: [osf.io/3navm](https://osf.io/3navm).

# Competing interests

We have no competing interests.

# Authors' contributions

P.E., M.P., and G.L. designed the research. P.E. conducted the research
and analyzed the data. P.E., M.P., and G.L. wrote the manuscript.

# Funding

This research was supported by NSF 1344279 awarded to G.L.

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
