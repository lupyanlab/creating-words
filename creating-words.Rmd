---
title: The emergence of words from vocal imitations
author:
  - name: Pierce Edmiston
    affiliation: 1
  - name: Marcus Perlman
    affiliation: 2
  - name: Gary Lupyan
    affiliation: 1
affiliation:
  - id: 1
    institution: University of Wisconsin-Madison
  - id: 2
    institution: Max Planck Institute for Psycholinguistics
bibliography: telephone.bib
csl: templates/nature.csl
output:
  pdf_document:
    template: templates/nat-hum-beh.tex
---

**People have long pondered the origins of language, especially the words that compose them [@Plato:1999uk; @Locke:1948eu]. Here, we report a large-scale experiment (_N_=1571) investigating how conventional spoken words might emerge from imitations of environmental sounds. Does the repeated imitation of an environmental sound gradually give rise to novel word forms? In what ways do these words resemble the original sounds that motivated them? Participants played a version of the children’s game “Telephone”. The first generation of participants imitated recognizable environmental sounds (e.g., glass breaking, water splashing). Subsequent generations imitated the imitations of the prior generation for a maximum of 8 generations. The results showed that the imitations became more stable and word-like, and easier to learn as category labels. At the same time, even after 8 generations, both spoken imitations and their written transcriptions could be matched above chance to the category of environmental sound that motivated them. These results show how repeated imitation can create progressively more word-like forms while continuing to retain a resemblance to the original sound that motivated them, and speak to the possible role of human vocal imitation in explaining the origins of at least some spoken words.**

```{r config, include=FALSE}
library(knitr)

opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  results="hide",
  fig.path="figs/",
  fig.width=6.8,
  fig.height=3,
  out.width="6.8in",
  out.height="3in",
  cache=TRUE,
  cache.path=".cache/",
  autodep=TRUE
)

sapply(list.files("R", "*.R", full.names = TRUE), read_chunk)
```

```{r setup, include=FALSE, cache=FALSE}
```

The importance of imitation and depiction in the origin of signs is clearly observable in the creation of words in signed languages [@Klima:1980si; @GoldinMeadow:2016bw; @Kendon:2014eg], but in considering the idea that vocal imitation may be key to understanding the origin of spoken words, many have argued that the human capacity for vocal imitation is far too limited to play a significant role [@Arbib:2012htb; @Tomasello:2010or; @Armstrong:2007go; @Corballis:2003ha; @Hockett:1978se; @Hewes:1973vr]. For example, Pinker and Jackendoff [@Pinker:2005cv] argued that, “most humans lack the ability… to convincingly reproduce environmental sounds… Thus ‘capacity for vocal imitation’ in humans might be better described as a capacity to learn to produce speech” (p. 209). Consequently, it is still widely assumed that vocal imitation---or more broadly, the use of any sort of resemblance between form and meaning---cannot be important to understanding the origin of spoken words.

Although most words of contemporary spoken languages are not clearly imitative in origin, there has been a growing recognition of the importance of imitative words in spoken languages [@Dingemanse:2015cu; @Perniss:2010fb] and the frequent use of vocal imitation and depiction in spoken discourse [@Clark:1990cl; @Lewis:2009wz]. This has led some to argue for the importance of imitation for understanding the origin of spoken words [e.g., @Brown:1955wy; @Donald:2016kd; @Imai:2014dea; @Perlman:2015ip; @Dingemanse:2014gj]. In addition, experiments show that counter to previous assumptions, people are highly effective at using vocal imitations in reference---in some cases, even more effective than with conventional words [@Lemaitre:2014kr]. Recent work has also shown that people are able to create novel imitative vocalizations for more abstract meanings (e.g. ‘slow’, ‘rough’, ‘good’, ‘many’) that are understandable to naïve listeners [@Perlman:2015ip]. The effectiveness of these imitations arises not because people can mimic environmental sounds with high fidelity, but because they are able to produce imitations that capture the salient features of sounds in ways that are understandable to listeners [@Lemaitre:2016kz]. Similarly, the features of onomatopoeic words might highlight distinctive aspects of the sounds they represent. For example, the initial voiced, plosive /b/ in “boom” represents an abrupt, loud onset, the back vowel /u/ a low pitch, and the nasalized /m/ a slow, muffled decay [@Rhodes:1994au].

Thus, converging evidence suggests that people can use vocal imitation as an effective means of communication. But can vocal imitations give rise to words that can be integrated into the vocabulary of a language? And if so, what is required for this to happen, and what happens to a vocal imitation in the course of it being turned into a word? To answer these questions, we recruited participants to play an online version of the children's game of "Telephone". In the children’s game, a spoken message is whispered from one person to the next. In our version, the original message or "seed sound" was a recording of an environmental sound. The initial group (first generation) of participants imitated these seed sounds, the next generation imitated the previous imitators, and so on for up to 8 generations. The final set of vocal imitations included `r n_final_imitations` imitations along `r n_branches` contiguous transmission chains from `r n_imitators` participants (Fig. 1a). 

```{r stability, include=FALSE}
```

```{r fig1, fig.cap="Stabilization of imitations through repetition. **a.** The design of the transmission chain experiment. Seed sounds (16) were sampled from four categories of environmental sounds: glass, tear, water, zipper. Participants imitated each seed sound, and then the next generation of participants imitated the imitations and so on for up to 8 generations. Chains are unbalanced due to random assignment and the exclusion of some low quality recordings. **b.** Change in perception of acoustic similarity over generations of repetition. Mean acoustic similarity ratings of imitations in each category are shown, along with the predictions of a hierarchical linear model with ±1 SE. Acoustic similarity increased over generations, indicating that repetition made the vocalizations easier to imitate with high fidelity. **c.** Transcription agreement for the first and last generation imitations of each transmission chain. Mean orthographic distance between the most frequent transcription and all other transcriptions of a given imitation are shown, with error bars as ±1 SE of the hierarchical linear model predictions. Transcriptions of later generation imitations were more similar to one another than transcriptions of first generation imitations, indicating that repeating imitations made them easier to transcribe into English orthography than direct imitations of environmental sounds."}
grid.arrange(
  gg_dendrogram,
  gg_similarity_judgments,
  gg_distance,
  nrow = 1
)
```

Imitations of environmental sounds became more stable over the course of being repeatedly imitated as revealed by increasing acoustic similarity along individual transmission chains. Research assistants (_N_=5) rated the acoustic similarity of pairs of imitations while blind to all conditions and hypotheses. Acoustic similarity ratings were fit with a linear mixed effects model predicting similarity from generation with random effects (intercepts and slopes) for rater and for seed sound nested within category. Imitations from later generations were rated as sounding more similar to one another than imitations from earlier generations, `r lmer_mod_results(similarity_judgments_lmertest_mod, "edge_generation_n")` (Fig. 1b). This result suggests that imitations became more stable (i.e., easier to imitate with high fidelity) with each generation.

Additional analyses of acoustic similarity using Mel-frequency cepstral coefficients (MFCCs) compared acoustic similarity for pairs of sounds sampled from the same and from different transmission chains. We calculated average acoustic similarities for six types of pairwise comparisons: within transmission chains (consecutive generations), within imitations from individual seed sounds, imitations from the same category, and imitations sampled between categories. These analyses revealed that imitations from the same transmission chain were the most similar to one another, followed by imitations from the same seed sound, and imitations from the same category. Imitations from different categories were the least similar to one another (Fig. SX).

As an additional test of stabilization, we had English-speaking participants transcribe first and last generation imitations into English orthography, and found that last generation imitations were transcribed with more consistency and agreement than first generation imitations. We collected a total of `r n_transcriptions` transcriptions---approximately `r n_transcriptions_per_imitation` transcriptions per sound. Some examples of the transcriptions are presented in Table 1. To measure the similarity among transcriptions, we calculated the orthographic distance between the most frequent transcription and all other transcriptions of a given imitation. The final orthographic distance measure was a ratio based on longest contiguous matching subsequences between pairs of transcriptions. We then fit a hierarchical linear model predicting orthographic distance from the generation of the imitation (First generation, Last generation) with random effects (intercepts and slopes) for seed sound nested within category. The results showed that transcriptions of last generation imitations were more similar to one another than transcriptions from first generation imitations, `r lmer_mod_results(orthographic_distance_lmertest_mod, "message_c")` (Fig. 1c). The same result is reached through alternative measures of orthographic distance for each imitation, such as the percentage of exact string matches, `r lm_mod_results(exact_string_matches_mod, "message_c")`, and the length of longest substring match, `r lmer_mod_results(substr_length_mod, "message_c")` (Fig. SX).

```{r table1, results='asis'}
table_caption <- "Examples of invented words."
kable(transcription_examples, caption = table_caption)
```

One consequence of imitations becoming more word-like is that they may make for better category labels. For example, an imitation from a later generation, by virtue of having a more word-like form, may be easier to learn as a label for the category of sounds that motivated it than an earlier imitation, which is more closely yoked to a particular environmental sound. To the extent that repeating imitations abstracts away the idiosyncrasies of a particular category member [@Edmiston:2015he; @Lupyan:2012cp], it may also be easier to generalize to new category members. We tested these predictions using a category learning task wherein participants had to learn novel labels for categories of environmental sounds. The novel labels were transcriptions generated either from first or last generation imitations gathered in our experiment. The procedure for selecting otherwise-equal transcriptions is detailed in the Methods. Here we report the consequences of learning either first or last generation transcriptions in the category learning experiment.

```{r learning, include=FALSE}
```

At the beginning of the experiment, where participants had to learn through trial-and-error which labels were associated with which sounds, participants learning transcriptions of first or last generation imitations did not differ in overall accuracy, `r glmer_mod_results(lsn_first_block_error_mod, "message_c", p_value_only = TRUE)`, or reaction time, `r lmer_mod_results(lsn_first_block_rt_mod, "message_c", p_value_only = TRUE)`. After this initial learning phase (i.e. after the first block of trials), accuracy performance quickly reached ceiling (Fig. SX) and did not differ between groups `r glmer_mod_results(lsn_after_first_block_error_mod, "message_c", p_value_only = TRUE)`. However, participants learning last generation transcriptions responded more quickly in subsequent blocks than participants learning first generation transcriptions, `r lmer_mod_results(lsn_after_first_block_lmertest_mod, "message_c")` (Fig. 2a). These faster responses suggest that, in addition to becoming more stable both in terms of acoustic and orthographic properties, repeating imitations makes them easier to learn as category labels. Given how quickly accuracy performance reached ceiling, further investigation with a more difficult category learning experiment is warranted (e.g., more than four categories and 16 exemplars).

Next, we examined whether transcriptions from last generation imitations were easier to generalize to novel sounds. To test this hypothesis, we compared RTs on trials immediately prior to the introduction of novel sounds (new category members) and the first trials after the block transition (±6 trials). The results revealed a reliable interaction between the generation of the transcribed imitation and the block transition, `r lmer_mod_results(transition_lmertest_mod, "block_transition_c:message_c")` (Fig. 2b). This result suggests that transcriptions from later generation imitations were easier to generalize to new category members. 

```{r fig2, fig.width=5.8, out.width="5.8in", fig.cap="Repeated imitations made for better category labels. Participants learned novel labels (transcriptions of first or last generation imitations) for categories of environmental sounds through trial-and-error. **a.** Mean RTs for correct responses in the category learning experiment with ±1 SE. Participants achieved faster RTs in matching transcribed labels to environmental sounds for labels transcribed from later compared to earlier generation imitations. **b.** Cost of generalizing to new category members with ±1 SE. After each block of trials, new environmental sounds were introduced, requiring participants to generalize the previously learned category labels to new category members. There was a generalization cost for first generation labels, but not last generation labels."}
grid.arrange(rt_plot, gg_transition, nrow = 1)
```

As the imitations became more word-like, were they stabilizing on arbitrary acoustic and orthographic forms, or did they maintain some resemblance to the original environmental sound that motivated them? To test this, we measured the ability of participants naïve to the design of the experiment to match imitations back to their original source relative to other seed sounds from either the same category or from different categories (Fig. 3a). All 365 imitations were tested in the three question types depicted in Fig. 3a. These questions differed in the relationship between the imitation and the four seed sounds provided as the choices in the question. Responses were fit by a hierarchical generalized linear model predicting match accuracy as different from chance (25%) based on the type of question being answered (True seed, Category match, Specific match) and the generation of the imitation.

```{r matching, include=FALSE}
```

Matching accuracy for all question types was above chance for the first generation of imitations, `r glmer_mod_results(imitation_matches_overall_mod, "(Intercept)", odds = TRUE)`, and decreased steadily over generations, `r glmer_mod_results(imitation_matches_overall_mod, "generation_1")`. We tested whether this increase in difficulty was constant across the three types of questions or if some question types became more difficult than others. The results are shown in Fig. 3b. Performance decreased over generations more rapidly for questions requiring a within-category distinction than for between-category questions, `r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_within")`, suggesting that between-category information was more resistant to loss through repeated imitation. An alternative explanation for this result is that the within-category match questions are simply more difficult because the sounds provided as choices are more acoustically similar to one another than the between-category questions, and therefore, performance might be expected to drop off more rapidly with repeated imitation for these more difficult questions[^below]. However, performance also decreased for the easiest type of question where the correct answer was the actual seed generating the imitation (True seed questions; see Fig. 3a); the advantage of having the true seed among between-category distractors decreased over generations, `r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_between")`. The observed increase in the "category advantage" (i.e., the advantage of having between-category distractors) combined with a decrease in the "true seed advantage" (the advantage of having the actual seed among the choices), shows that the changes induced by repeated imitation caused the imitations to lose some of properties that linked the earlier imitations to the specific sound that motivated them, while nevertheless preserving a more abstract category-based resemblance.

[^below]: We observed that performance on some Specific match questions dropped below chance for later generations indicating participants had an apparent aversion to the nominally correct answer. Additional analyses showed that participants were not converging on a single incorrect response. The reason for this pattern is at present unclear. Removing these trials from the analysis does not substantively change the conclusions.

We next tested whether it was possible to match the written transcriptions of the auditory sounds back to the original environmental sounds. Participants were given a novel word (the most frequent transcriptions of first and last generation imitations) and had to guess the sound that was represented by the invented word. The distractors for all questions were between-category, i.e. true seed and category match. Specific match questions were omitted.

Remarkably, participants were able to guess the correct meaning of a word that was transcribed from an imitation that had been repeated up to 8 times, `r glmer_mod_results(transcription_matches_last_gen_mod, "(Intercept)", odds = TRUE)` (Fig. 3c). This was true for True seed questions containing the actual seed generating the transcribed imitation, `r glmer_mod_results(transcription_matches_last_gen_mod_category, "(Intercept)")`, and for Category match questions where participants had to associate transcriptions with a particular category of environmental sounds, `r glmer_mod_results(transcription_matches_last_gen_mod_exact, "(Intercept)")`. The effect of generation did not vary across these question types, `r glmer_mod_results(acc_mod, "question_c:message_c")`.

```{r fig3, fig.cap='Repeated imitations retained a resemblance to the category of environment sounds that motivated them. **a.** Three types of matching questions used to assess the resemblance between the imitation (and transcriptions of imitations) and the original seed sounds. For each question, participants listened to an imitation (dashed circles) and had to guess which of 4 sound choices (solid circles) they thought the person was trying to imitate. True seed questions contained the actual sound that generated the imitation as one of the choices (correct response). The remaining sounds were sampled from different categories. Category match questions replaced the original seed sound with another sound from the same category. Specific match questions pitted the actual seed against the other seeds within the same category. **b.** Change in matching accuracy over generations of imitations, shown as predictions of the generalized linear models with ±1 SE of the model predictions. The "category advantage" (Category match vs. Specific match) increased over generations, while the "true seed advantage" (True seed v. Category match) decreased (see main text), suggesting that imitations lose within-category information more rapidly than between-category information. **c.** Change in matching accuracy over generations of imitations transcribed into English-sounding words. Imitations and transcriptions of imitations could still be matched back to the category of sound that motivated the original imitation even after 8 generations. Match accuracy for imitations is shown for comparison.'}
q_true_seed <- read_graphviz("true-seed", "wordsintransition")
q_category_match <- read_graphviz("category-match", "wordsintransition")
q_specific_match <- read_graphviz("specific-match", "wordsintransition")

grid.arrange(
  arrangeGrob(q_true_seed, q_category_match, q_specific_match, ncol = 1,
              top = textGrob('a', hjust = 1, gp = gpar(fontsize = 16))),
  gg_match_to_seed,
  gg_match_transcriptions,
  nrow = 1
)
```

In sum, our results show how unguided repetition causes initial imitations of environmental sounds transition to more word-like forms. They suggest that in the course of this transition, the imitations become more categorical and more effective as learned category labels all while retaining some resemblance to the environmental sounds that motivated them.

Imitative (or "iconic") words are found across the spoken languages of the world [@Dingemanse:2015cu; @Imai:2014dea; @Perniss:2010fb]. Counter to past assumptions about the limitations of human vocal imitation, people are surprisingly effective at using vocal imitation to represent and communicate about the sounds in their environment [@Lemaitre:2016kz] and more abstract meanings [@Perlman:2015ip], making the hypothesis that early spoken words originated from imitations a plausible one. We examined whether simply repeating an imitation of an environmental sound---with no intention to create a new word or even to communicate---produces more word-like forms.

Our results show that through simple repetition, imitative vocalizations became more word-like both in form and function. In form, the vocalizations gradually stabilized over generations, becoming more similar from imitation to imitation. They also became increasingly standardized in accordance with English orthography, as later generations were more consistently transcribed into English words. In function, the increasingly word-like forms became more effective as category labels. In a category learning experiment, naïve participants were faster to learn category labels derived from transcriptions of later-generation imitations than those derived from direct imitations of the environmental sound. This fits with previous research showing that the relatively arbitrary forms that are typical of words (e.g. “dog”) makes them better suited to function as category labels compared to direct auditory cues [e.g. the sound of a dog bark; @Lupyan:2012cp; @Edmiston:2015he; @Boutonnet:2015fz].

Evan as the vocalizations became more word-like, they nevertheless maintained an imitative quality. After eight generations they could no longer be matched to the particular sound from which they originated any more accurately than they could be matched to the general category of environmental sound. Thus, information that distinguished an imitation from other sound categories was more resilient to transmission decay than exemplar information within a category. Remarkably, even after the vocalizations were transcribed into English orthography, participants were able to guess their original sound category from the written “word”.  In contrast to the vocalizations, participants continued to be more accurate at matching late generation transcriptions back to their particular source sound relative to other exemplars from the same category.

Although the number of imitative words in contemporary languages may appear to be very small [@Crystal:1987en; @Newmeyer:1992we], increasing evidence from disparate languages shows that vocal imitation is, in fact, a widespread source of vocabulary. Cross-linguistic surveys indicate that onomatopoeia---imitative words used to represent sounds---are a universal lexical category found across the world's languages [@Dingemanse:2012fc]. Even English, a language that has been characterized as relatively limited in iconic vocabulary [@Vigliocco:2014fc], is documented to have hundreds of clearly imitative words including words for human and animal vocalizations as well as various types of environmental sounds [@Rhodes:1994au; @Sobkowiak:1990ph]. Besides words that are directly imitative of sounds---the focus of the present study---many languages contain semantically broader inventories of ideophones. These words comprise a grammatically and phonologically distinct class of words that are used to express various sensory-rich meanings, such as qualities related to manner of motion, visual properties, textures and touch, inner feelings and cognitive states [@Dingemanse:2012fc; @Nuckolls:1999ca; @Voeltz:2001vv]. As with onomatopoeia, ideophones are often recognized by naïve speakers as bearing a degree of resemblance to their meaning [@Dingemanse:2016vd].

Our study focused on imitations of environmental sounds and more work remains to be done to determine the extent to which vocal imitation can ground de novo vocabulary creation in other semantic domains [e.g., @Perlman:2015ip; @Lupyan:2015vic]. What the present results make clear is that the transition from imitation to word can be a rapid and simple process: the mere act of repeated imitation can drive vocalizations to become more word-like in both form and function. Notably, just as onomatopoeia and ideophones of natural languages maintain a resemblance to the quality they represent, the present vocal imitations transitioned to words while retaining a resemblance to the original sound that motivated them.

# Methods

**Data availability.** The data that support the findings of this study, along with all methods, materials, and analyses, are available in public repositories through the Open Science Framework page for this research at [osf.io/3navm](https://osf.io/3navm).

**Analyses.** Degrees of freedom and corresponding significance tests for hierarchical linear models were estimated using the Satterthwaite approximation [@lmerTest:2016].

**Selecting seed sounds.** To avoid sounds having lexicalized or conventionalized onomatopoeic forms in English, we used inanimate categories of environmental sounds. Using an odd-one-out norming procedure (_N_=`r n_norming_subjects` participants; see Supporting Information), an initial set of 36 sounds in 6 categories was reduced to a final set of 16 "seed" sounds: 4 sounds in each of 4 categories (Figs. 5-6). The four final categories were: water, glass, tear, zipper.

**Collecting imitations.** Participants (_N_=`r n_imitators`) recruited from Amazon Mechanical Turk were paid to participate in an online version of the children's game of "Telephone". Participants were instructed that they would hear some sound and their task is to reproduce it as accurately as possible using their computer microphone (Fig. 7). Full instructions are provided in the Supporting Information. Participants listened to and imitated 4 sounds, receiving one sound from each of the four categories of sounds drawn at random such that participants were unlikely to hear the same person more than once. Recordings that were too quiet (less than --30 dBFS) were not allowed. Imitations were monitored by an experimenter to catch any gross errors in recording before they were heard by the next generation of imitators (Fig. 8). For example, recordings were trimmed to the length of the imitation, and recordings with loud sounds in the background were removed. The experimenter also blocked sounds that violated the rules of the experiment, e.g., by saying something in English. A total of `r n_removed` (`r n_removed_pct`%) imitations were removed prior to subsequent analysis.

**Measuring acoustic similarity.** Acoustic similarity was measured by having research assistants listen to pairs (approx. 314) of sounds and rate their subjective similarity. On each trial, raters heard two sounds from subsequent generations were played in succession but in random order. They then indicated the similarity between the sounds on a 7-point Likert scale from _Entirely different and would never be confused_ to _Nearly identical_. Raters were encouraged to use as much of the scale as they could while maximizing the likelihood that, if they did this procedure again, they would reach the same judgments. Full instructions are provided in the Supporting Information. Ratings were normalized (z-scored) prior to analysis.

**Collecting transcriptions of imitations.** Participants (_N_=`r n_transcribers`) recruited from Amazon Mechanical Turk were paid to transcribe sounds into words in an online survey. They listened to imitations and were instructed to write down what they heard as a single word so that the written word would sound as much like the message as possible. Exact instructions are provided in the Supporting Information (Fig. 9).

Transcriptions were generated from the first and last three generations of all imitations collected in the Telephone game; that is, not all imitations were transcribed (Fig. 10). Participants also provided transcriptions of the original environmental seed sounds (Fig. 11). Transcriptions from participants who failed a catch trial were excluded (_N_=`r n_bad_transcribers`), leaving `r n_transcriptions` transcriptions for analysis. Of these, `r n_english_transcriptions` transcriptions (8%) were removed because they contained English words, which was a violation of the instructions of the experiment.

**Learning transcriptions as category labels.** Our transmission chain design and subsequent transcription procedure created `r n_created_words` unique words. From these, we sampled words transcribed from first and last generation imitations as well as from seed sounds that were equated in length and overall matching accuracy. Specifically, we removed transcriptions that contained less than 3 unique characters and transcriptions that were over 10 characters long. Of the remaining transcriptions, a sample of `r n_lsn_words` were selected using a bootstrapping procedure to have approximately equal means and variances of overall matching accuracy. The full procedure for sampling the words in this experiment is described in the Supporting Information.

Participants (_N_=`r n_all_lsn_subjs`) were University of Wisconsin undergraduates who received course credit for participation. Participants were randomly assigned four novel labels to learn for four categories of environmental sounds. Participants were assigned between-subject to learn labels (transcriptions) of the first or last generation imitations, as well as labels from transcriptions of seed sounds as a control (Fig. 15). On each trial, participants heard one of the 16 seed sounds. After a 1s delay , participants saw a label--one of the transcribed imitations--and responded yes or no using a gamepad controller depending on whether the sound and the word went together. Participants received accuracy feedback (a bell if correct; a buzzing sound if incorrect). Four outlier participants were excluded from the final sample due to high error rates and slow RTs.

Participants categorized all 16 seed sounds over the course of the experiment, but they learned them in blocks of 4 sounds at a time. Within each block of 24 trials, participants heard the same four sounds and the same four words multiple times, with a 50% probability of the sound matching the word on any given trial. At the start of a new block of trials, participants heard four new sounds they had not heard before, and had to learn to associate these new sounds with the words they had learned in the previous blocks.

**Matching imitations to seed sounds.** Participants (_N_=`r n_all_matching_imitations`) recruited from Amazon Mechanical Turk were paid to listen to imitations, one at a time, and for each one, choose one of four possible sounds they thought the person was trying to imitate. The task was unspeeded and no feedback was provided. Participants completed 10 questions at a time.

Question types (True seed, Category match, Specific match) were assigned between-subject. Participants in the True seed and Category match conditions were provided four seed sounds from different categories as choices in each question. Participants in the Specific match condition were provided four seed sounds from the same category. All `r n_final_imitations` imitations were tested in each of the three conditions.

**Matching transcriptions to seeds.** Participants (_N_=`r n_all_transcription_match_subjs`) recruited from Amazon Mechanical Turk completed a modified version of the matching survey. Instead of listening to imitations, participants now read a word (a transcription of an imitation), which they were told was an invented word. They were instructed that the word was invented to describe one of the four presented sounds, and they had to guess which one. Of all the unique transcriptions that were collected for each sound (imitations and seed sounds), only the top four most frequent transcriptions were used in the matching experiment. `r n_transcription_match_subjs_failed_catch_trial` participants failed a catch trial and were excluded, leaving `r n_transcription_match_subjs` participants in the final sample.

# References
