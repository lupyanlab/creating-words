---
title: The emergence of words from iterated vocal imitation
author: |
  Pierce Edmiston, Marcus Perlman, and Gary Lupyan  
  University of Wisconsin-Madison
output:
  beamer_presentation:
    theme: metropolis
    keep_tex: true
---

```{r config, include=FALSE}
library(knitr)
opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, results="hide", cache=TRUE, cache.path="talk_cache/")
read_chunk("analysis.R", labels = "main")
```

```{r main, include=FALSE}
```

# Are names for things natural or conventional?

```{r cratylus-dialogue, engine="dot"}
digraph {
  rankdir=LR;
  fontname=Helvetica;
  label="Plato's Cratylus";
  labelloc=t;
  node[shape="none" fontname=Helvetica];
  edge[arrowhead="vee" arrowtail="vee"];
  Cratylus -> Hermogenes[dir=both minlen=2 shape=circle];
  Cratylus[label="Cratylus\n'Natural!'"];
  Hermogenes[label="Hermogenes\n'Conventional!'"];
}
```

<!--
I want to start with a very old question about language, and
about where names come from, and that is,
are names for things natural or are they conventional?

Are some names better than others, or
are all names created equal and to some extent interchangeable?

This is the question that Plato explored in his _Cratylus_ dialogue,
which is an argument between Cratylus and Hermogenes.

Cratylus argues that names for things are not arbitrarily decided
because some names seem better or more natural than others.

Hermogenes argues the exact opposite,
that only convention could determine which names are used
to designate which objects.

In the dialogue, Plato makes the point that both views
are probably wrong in the extremes, but
lucky for us,
they didn't come to a firm conclusion, and this question has been
the topic of much discussion for many hundreds of years.
-->

# Which is more important to language evolution?

```{r lupyanlab-dialogue, engine="dot"}
digraph {
  rankdir=LR;
  node[shape="none" fontname=Helvetica fontcolor=white fontsize=20];
  edge[arrowhead="vee" arrowtail="vee"];
  marcus -> pierce[dir=both minlen=2 shape=none];
  marcus[label="Iconicity!" image="img/marcus.png" labelloc=b];
  pierce[label="Arbitrariness!" image="img/pierce.png" labelloc=b];
}
```

<!--
I bring this up because it's reminiscent of a similar dialogue I
had with Marcus Perlman, back when we started this project.

The debate we had was this:

Which is a more important contributor to language evolution?
Iconicity,
or what Plato might have called the "naturalness of some names",
or arbitrariness,
the idea that words do not have to resemble their meanings?

In the past, I've argued for the arbitrariness side of this equation.
What I've said is that
the reason language is so advantageous
is not because it allows us to refer to specific things,
but that it allows us to group together categories of things,
irrespective of the individual members.

Through arbitrariness, you get categorization and symbolic reasoning.

In contrast, Marcus has argued for the role of iconicity in language evolution.
He thinks that the
widespread belief that languages today are entirely arbitrary is bogus.
In fact, iconicity pervades languages, even ones like English and
Spanish that are thought to be largely arbitrary.

The reason widespreaad iconicity could be important for language evolution
is that iconic names may be easier to learn.
In a project with Lynn Perry,
they found that words that were rated
as more iconic were also learned earlier in a child's life.

So Marcus, Gary, and I got together to try to figure out these differences.
Specifically what we were after is a way to see between
this dichotomy, to see the advantages of iconicity when creating
words, but also to observe the advantages of more symbolic
mappings for things like categorization.
-->

# Onomatopoeic words are found across languages

```{r onomatopoeia-comics, fig.cap="By James Chapman."}
gridExtra::grid.arrange(
  crotchet::read_image("img/chapman-clap.png"),
  crotchet::read_image("img/chapman-sneeze.png"),
  nrow = 1
)
```

<!--
We decided to look specifically at the creation of onomatopoeic words,
which are found across languages.

What's interesting about these onomatopoeic words is that they are all very
clearly imitating the same sound, clapping or sneezing, and yet
they are all spelled differently, so they behave like conventional words in a language
as well as imitations.

We wanted to see what it took to create new onomatopoeic words.
Do all words including onomatopoeic words need to be coined conventionally,
or can onomatopoeic words actually emerge gradually from the imitations themselves?
-->

# Can words emerge from iterated imitation?

```{r telephone-chain, engine="dot"}
digraph {
  rankdir=LR;
  node[fontname=Helvetica shape=circle];
  0 -> 1 -> 2 -> 3 -> 4 -> 5;
  0[shape="none" label="imitation"];
  5[shape="none" label="?"];
}
```

<!--
Specifically what we asked was whether words can emerge from
iterated imitations.

We were interested in the minimal conditions for observing
an emergence of words from imitations.
Without any instruction or intention to create a word,
does simply repeating it cause it to become more wordlike?

To test this we had participants imitate various environmental sounds,
sounds like glass breaking, and water splashing,
and then we had new participants imitate the imitations,
and so on for generation after generation.

What we measured was how the imitation changed as a function of
generation of repetition.

Is repeating an imitation over and over across generations of different
speakers sufficient to make it more wordlike?
-->

# Interface for collecting vocal imitations

```{r telephone-game}
crotchet::draw_image("collect-imitations-gui", "wordsintransition")
```

<!--
Here's what the experiment looked like.

It was basically our version of the children's game of telephone.

Participants clicked on the top speaker to hear a sound,
and the bottom speaker to make their imitation of it.

And participants were instructed to copy whatever they heard as accurately as possible.
-->

# The results of the transmission chain experiment

```{r}
gg_dendrogram
```

<!--
And here are our results -- the imitations we collected in this
transmission chain experiment.

We had four different categories of environmental sounds:
water, glass, tearing, and zipper,
and four seed sounds within each category.

The first generation of participants imitated the seed sound,
and later generations imitated the previous generation,
for a maximum of 8 generations.
-->

# Research questions

1. Do repeated imitations stabilize on particular words?
2. Do the imitations retain their resemblance to the seed sound?
3. Do the imitations become more suitable as category labels?

<!--
Once we collected these imitations, we sought to answer three questions
about how the imitations changed as a function of repetition.

First, do the imitations in each chain stabilize on particular words?

Are later generation imitations more similar to one another than earlier
generation imitations?

Next we asked what the imitations were stabilizing on. Do the imitations
retain a resemblance to the original seed sound, or does each chain
careen off to create a total nonsence word.

Finally, we asked whether repetition has any reprecussions for the
language learner. We took words created at the beginning of the
chains and at the end of the chains, and test them to see which served
as better category labels in a category learning experiment.
-->

# Repeated imitations became more similar

```{r similarity-judgments}
gg_similarity_judgments
```

# Similarity increased within, not between, chains

```{r algorithmic-similarity}
gg_algo_similarity
```

# Example transcriptions

```{r example-transcriptions, results="asis"}
kable(transcription_examples)
```

# Repeated imitations were transcribed more consistently

```{r transcription-distance}
gg_distance
```

# 1. Do imitations stabilize on particular words?

**Yes.** Repeating imitations makes them more similar to one another acoustically and orthographically.

_But what are they stabilizing on?_

# Interface for matching imitations to seed sounds

```{r guess-the-seed}
draw_image("match-imitations-gui", "wordsintransition")
```

# Types of matching questions

```{r matching-questions}
grob_question_types <- arrangeGrob(
  read_graphviz("true-seed", "wordsintransition"),
  read_graphviz("category-match", "wordsintransition"),
  read_graphviz("specific-match", "wordsintransition"),
  ncol = 1
)
grid::grid.draw(grob_question_types)
```

# Category information was the most resilient to decay

```{r matching-imitations}
grid.arrange(
  grob_question_types,
  gg_match_to_seed,
  nrow = 1
)
```

# Transcriptions can retain category informations

```{r matching-transcriptions}
gg_match_transcriptions
```

# 2. Do imitations retain a resemblance to the seed sound?

**Yes** (at least for 8 generations with 4 categories).

_What are the consequences of repeating imitations for learners?_

# A simple category learning experiment

```{r learning-sound-names-paradigm, engine="dot"}
digraph {
  rankdir=LR;
  node[fontname="Helvetica" shape=none];
  sound -> label -> prompt[minlen=2];
  sound[label="sound\n<water>\n 1/16"];
  label[label="word\n'eeverlusha'\n 1/4"];
  prompt[label="?\nY/N"];
}
```

# No difference in accuracy for novel labels

```{r learning-performance-ceiling}
gg_lsn_performance_ceiling
```

# Later generation labels yielded faster responses

```{r learning-rts}
rt_plot
```

# Later generation labels were generalized more quickly

```{r learning-generalization}
gg_transition
```

# The emergence of words from iterated vocal imitation

1. Do repeated imitations stabilize on particular words?
2. Do the imitations retain their resemblance to the seed sound?
3. Do the imitations become more suitable as category labels?

# Thanks!

Pierce Edmiston, Marcus Perlman, and Gary Lupyan.
[github.com/lupyanlab/creating-words](https://github.com/lupyanlab/creating-words/tree/cesc)  
[osf.io/3navm](https://osf.io/3navm)  

# Correlation between subjective and objective similarity

```{r comparing-similarities}
gg_comparing_similarities
```

# Transcriptions of seeds were the least consistent

```{r transcription-of-seeds-distance}
gg_seed_distance
```

# Match accuracies for imitations and transcriptions

```{r matching-accuracies}
grid.arrange(
  gg_match_to_seed,
  gg_match_transcriptions + theme(axis.title.y = element_blank()),
  nrow = 1
)
```

# Transcriptions of seed sounds were matched very accurately

```{r matching-transcriptions-of-seeds}
gg_seed_matching
```

# Transcriptions of seed sounds ???

```{r learning-transcriptions-of-seeds}
gg_seed_rt_plot
```
