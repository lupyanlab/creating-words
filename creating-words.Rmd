---
title             : "Repeated imitation makes human vocalizations more word-like"
shorttitle        : "Words from imitations"

author:
  - name          : "Pierce Edmiston"
    affiliation   : "1"
    corresponding : yes
    address       : "1202 W. Johnson St., Madison, WI, 53703"
    email         : "pedmiston@wisc.edu"
  - name          : "Marcus Perlman"
    affiliation   : "2"
  - name          : "Gary Lupyan"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Wisconsin-Madison"
  - id            : "2"
    institution   : "University of Birmingham"

author_note: >
  Pierce Edmiston and Gary Lupyan, Department of Psychology, University of
  Wisconsin-Madison, Madison, Wisconsin. Marcus Perlman, Department of English
  Language and Applied Linguistics, University of Birmingham, United Kingdom.
abstract: >
  People have long pondered the evolution of language and the origin of words.
  Here, we investigate how conventional spoken
  words might emerge from imitations of environmental sounds. Does the repeated
  imitation of an environmental sound gradually give rise to more word-like
  forms? In what ways do these forms resemble the original sounds that motivated
  them (i.e., exhibit iconicity)? Participants played a version of the
  children’s game “Telephone”. The first generation of participants imitated
  recognizable environmental sounds (e.g., glass breaking, water splashing).
  Subsequent generations imitated the previous generation of imitations for a
  maximum of 8 generations. The results showed that the imitations became more
  stable and word-like, and later imitations were easier to learn as category
  labels. At the same time, even after 8 generations, both spoken imitations and
  their written transcriptions could be matched above chance to the category of
  environmental sound that motivated them. These results show how repeated
  imitation can create progressively more word-like forms while continuing to
  retain a resemblance to the original sound that motivated them, and speak to
  the possible role of human vocal imitation in explaining the origins of at
  least some spoken words.
keywords          : "language evolution, iconicity, vocal imitation, transmission chain"
wordcount         : "7229"

bibliography      : ["references.bib"]

figsintext        : yes
figurelist        : yes
tablelist         : yes
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
csl               : "proceedings-of-the-royal-society-b.csl"
output            :
  papaja::apa6_pdf:
    keep_tex: yes
---

```{r config, include=FALSE}
library(knitr)

opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  results="hide",
  cache=TRUE,
  fig.width=4,
  fig.height=4
)

sapply(list.files("R", "*.R", full.names = TRUE), read_chunk)
```

```{r setup, include=FALSE, cache=FALSE}
```

Most vocal communication of non-human primate species is based on
species-typical calls that are highly similar across generations and between
populations [@Seyfarth:1986tw; @Crockford:2004cz]. In
contrast, human languages comprise a vast repertoire of learned meaningful
elements (words and other morphemes) which can number in the tens of thousands
or more [e.g., @Brysbaert:2016fg]. Aside from their number, the words of
different natural languages are characterized by their extreme diversity
[@Wierzbicka:1996sm; @Evans:2009dk; @Lupyan:2016uw]. The words used within a
speech community change relatively quickly over generations compared to the
evolution of vocal signals [e.g., @Pagel:2007br]. At least in part as a
consequence of this divergence, most words appear to bear a largely arbitrary
relationship between their form and their meaning --- seemingly, a product of
their idiosyncratic etymological histories [@Sapir:1921; @Labov:1972]. The
apparently arbitrary nature of spoken vocabularies presents a quandary for the
study of language origins. If words of spoken languages are truly arbitrary, by
what process were the first words ever coined?

While the origin of most spoken words is hard to discern, the situation is
somewhat different for signed languages. In signed languages, the origins of
many signs are relatively transparent. Although signed languages rely on the
same type of referential symbolism as spoken languages, many individual signs
have clear iconic roots, formed from gestures that resemble their meaning
[@GoldinMeadow:2016bw; @Kendon:2014eg; @Klima:1980si]. For instance,
@Frishberg:1975dh noted the iconic origins of the American Sign Language (ASL)
sign for 'bird', which is formed with a beak-like handshape articulated in front
of the nose. Another example is 'steal', derived from a grabbing motion to
represent the act of stealing something. @Stokoe:1965 identified about 25% of
American Sign Language signs to be iconic, and reviewing the remaining 75% of
ASL signs, @Wescott:1971to determined that about two-thirds of these seemed
plausibly derived from iconic origins. Further support for iconic origins of
signed languages comes from observations of deaf children raised without
exposure to a signed language, who develop homesign systems to use with their
family. These communication systems are generally built from a process in which
the children establish conventional gestures through the use of pantomimes and
various iconic and indexical gestures [e.g. @GoldinMeadow:1977gz]. Participants
in laboratory experiments utilize a similar strategy when they communicate with
gestures in iterated communication games [@Fay:2014cw].

In contrast to the visual gestures of signed languages, many have argued that
iconic vocalizations could not have played a significant role in the origin of
spoken words because the vocal modality simply does not afford much resemblance
between form and meaning [@Arbib:2012htb; @Armstrong:2007go; @Corballis:2003ha;
@Hewes:1973vr; @Hockett:1978se; @Tomasello:2010or]. It has also been argued that
the human capacity for vocal imitation is a domain-specific skill, geared
towards learning to speak, rather than the representation of environmental
sounds. For example, @Pinker:2005cv suggested that, “most humans lack the
ability… to convincingly reproduce environmental sounds… Thus ‘capacity for
vocal imitation’ in humans might be better described as a capacity to learn to
produce speech” (p. 209). Consequently, it is still widely assumed that vocal
imitation --- or more broadly, the use of any sort of resemblance between form
and meaning --- cannot be important to understanding the origin of spoken words.

Although most words of contemporary spoken languages are not clearly imitative
in origin, there has been a growing recognition of the importance of iconicity
in spoken languages [@Dingemanse:2015cu; @Perniss:2010fb] and the common use of
vocal imitation and depiction in spoken discourse [@Clark:1990cl;
@Lewis:2009wz]. This has led some to argue for the importance of imitation for
understanding the origin of spoken words [e.g., @Brown:1955wy;
@Dingemanse:2014gj; @Donald:2016kd; @Imai:2014dea; @Perlman:2015ip]. In
addition, counter to previous assumptions, people are highly effective at using
vocal imitations to refer to environmental sounds such as coins dropping in a
jar or mechanical events such as scraping --- in some cases, even more effective
than when using conventional words [@Lemaitre:2014kr]. These imitations are
effective not because people can mimic environmental sounds with high fidelity,
but because people are able to produce imitations that capture the salient
features of the referent in ways that are understandable to listeners
[@Lemaitre:2016kz]. Similarly, the features of onomatopoeic words might
highlight distinctive aspects of the sounds they represent. For example, the
initial voiced, plosive /b/ in “boom” represents an abrupt, loud onset, the back
vowel /u/ a low pitch, and the nasalized /m/ a slow, muffled decay
[@Rhodes:1994au]. Recent work has also shown that people are able to create
novel imitative vocalizations for more abstract meanings (e.g. ‘slow’, ‘rough’,
‘good’, ‘many’) that are understandable to naïve listeners [@Perlman:2015ip].

Thus, converging evidence suggests that people can use vocal imitation as an
effective means of communication. At the same time, vocal imitations are not
words. If vocal imitation played a role in the origin of some spoken words, then
it is necessary to identify whether vocal imitation
can give rise to more word-like vocalizations that can eventually be integrated
into a vocabulary of a language. In the present set of studies we ask whether
vocal imitations can transition to more word-like forms through sheer repetition
--- without an explicit intent to communicate. To answer this question, we
recruited participants to play an online version of the children's game of
"Telephone". In the children’s game, a spoken message is whispered from one
person to the next. In our version, the original message or "seed sound" was a
recording of an environmental sound. The initial group of participants (first
generation) imitated these seed sounds, the next generation imitated the
previous imitators, and so on for up to 8 generations.

Our approach uses a transmission chain methodology similar to that frequently
used in experimental studies of language evolution [@Tamariz:2017bd, for
review]. As with other transmission chain studies (and iterated learning studies
more generally), we seek to discover how various biases and constraints of
individuals change the nature of a linguistic signal. Importantly, while typical
transmission chain studies focus on the impact of learning biases [e.g.,
@Kirby:2008kja], the present studies involve iterated reproduction that does not
involve any learning. Participants simply attempt to imitate a sound as best as
they can. The biases we hypothesize to drive vocalizations to become more
word-like are therefore not related to any learning process, but instead are
expected to emerge from constraints on the reproducibility of vocalizations. Our
aim is thus to determine whether iterated reproduction, even without learning,
is a sufficient enough constraint to enable the emergence of more word-like
signals.

After collecting the imitations, we conducted a series of analyses and
additional experiments to systematically answer the following questions: First,
do imitations stabilize in form and become more word-like as they are repeated?
Second, do the imitations retain a resemblance to the original environmental
sound that inspired them? If so, it should be possible for naïve participants to
match the emergent words back to the original seed sounds. Third, do the
imitations become more suitable as categorical labels for the sounds that
motivated them? For example, does the imitation of a particular water-splashing
sound become, over generations of repeated imitation, a better label for the
more general category of water-splashing sounds?

# Experiment 1: Stabilization of imitations through repetition

```{r stability, include=FALSE}
```

In the first experiment, we collected the vocal imitations, and assessed the
extent to which repeating imitations of environmental sounds results in
progressive stabilization toward more word-like forms in three ways. First, we
measured changes in the perception of acoustic similarity between subsequent
generations of imitations. Second, we used algorithmic measures of acoustic
similarity to assess the similarity of imitations sampled within and between
transmission chains. Third, we obtained transcriptions of imitations, and
measured the extent to which later generation imitations were transcribed with
greater consistency and agreement. The results show that repeated imitation
results in vocalizations that are easier to repeat with high fidelity and more
consistently transcribed into English orthography.

## Methods

### Selecting seed sounds

To avoid sounds with lexicalized or conventionalized onomatopoeic forms in
English, we used inanimate categories of environmental sounds. To select sounds
that were equally distinguishable within each category, we used an odd-one-out
norming procedure (_N_=`r n_norming_subjects` participants; see Fig. S1),
resulting in a final set of 16 sounds, 4 in each of 4 categories: glass, tear,
water, zipper.

### Collecting vocal imitations

Participants (_N_=`r n_imitators`) recruited from Amazon Mechanical Turk were
paid to participate in an online version of the children's game of "Telephone".
Participants were instructed that they would hear some sound and their task was
to reproduce it as accurately as possible using their computer microphone. Full
instructions are provided in the Supplemental Materials.

Each participant listened to and imitated four sounds: one from each of the four
categories of environmental sounds. Sounds were assigned at random such that
participants were unlikely to imitate the same person more than once.
Participants were allowed to listen to each target sound as many times as they
wished, but were only allowed a single recording in response. Recordings that
were too quiet (less than -30 dBFS) were not accepted.

Imitations were monitored by an experimenter to remove poor quality recordings
(e.g., loud background sounds), and recordings that violated the rules of
the experiment (e.g., an utterance in English). A total of `r n_removed`
(`r n_removed_pct`%) imitations were removed. The final sample contained
`r n_final_imitations` imitations along `r n_branches` contiguous transmission
chains (Fig. 1).

```{r fig1, fig.width=4, fig.height=3.5, fig.cap="Vocal imitations collected in the transmission chain experiment. Seed sounds (16) were sampled from four categories of environmental sounds: glass, tear, water, zipper. Participants imitated each seed sound, and then the next generation of participants imitated the imitations, and so on, for up to 8 generations. Chains are unbalanced due to random assignment and the exclusion of some low quality recordings."}
gg_dendrogram
```

### Measuring acoustic similarity

Acoustic similarity judgments were obtained from five research assistants who
listened to pairs of sounds (approx. 300) and rated their subjective similarity.
On each trial, raters heard two sounds from subsequent generations played in
random order, and indicated the similarity between the sounds on a 7-
point Likert scale from _Entirely different and would never be confused_ to
_Nearly identical_. Full instructions and inter-rater reliability measures are
provided in the Supplemental Materials.

To obtain algorithmic measures of acoustic similarity, we used the acoustic
distance functions included in Phonological Corpus Tools [@PCT:1.1]. We computed
Mel-frequency cepstral coefficients (MFCCs) between pairs of imitations using 12
coefficients in order to obtain speaker-independent estimates.

### Collecting transcriptions of imitations

Transcriptions were obtained for the first and last three generations of each
transmission chain. Additional “transcriptions” of the original sounds used as
seeds were also collected and are analyzed in the Supplementary Materials (Fig.
S6).

Participants (_N_=`r n_transcribers`) recruited from Amazon Mechanical Turk
were paid to listen to imitations and write down what they heard as a
single "word" so that the written word would sound as much like the sound as
possible. Participants were instructed to avoid transcribing the imitations
into existing English words. Each participant completed 10 transcriptions.

## Results

Imitations of environmental sounds became more stable over the course of
being repeated as revealed by increasing acoustic similarity judgments along
individual transmission chains. Acoustic similarity ratings were fit with
a linear mixed-effects model predicting perceived acoustic similarity from
generation with random effects (intercepts and slopes) for raters. To test
whether the hypothesized increase in acoustic similarity was true across all
seed sounds and categories, we added random effects (intercepts and slopes)
for seed sounds nested within categories. The results showed that, across
raters and seeds, imitations from later generations were rated as sounding
more similar to one another than imitations from earlier generations,
`r lmer_mod_results(similarity_judgments_lmertest_mod, "edge_generation_n")`
(Fig. 2). This result suggests that imitations became more stable (i.e., easier
to imitate with high fidelity) with each generation of repetition.

```{r fig2, fig.cap="Change in perception of acoustic similarity over generations of iterated imitation. Points depict mean acoustic similarity ratings for pairs of imitations in each category. The predictions of the linear mixed-effects model are shown with ±1 SE."}
gg_similarity_judgments
```

Although in some chains imitations were repeated up to 8 times, we found
evidence that increasing similarity could be detected after fewer repetitions,
in as little as 5 generations. Imitations from chains that did not reach 5
generations due to experimental constraints (see Fig. 1) were included in all
analyses, which included appropriate random effects to assure that these shorter
chains were not treated equally to longer chains. However, chains with fewer
than 5 generations were excluded from analyses involving transcriptions of the
first and last imitation in each chain because these analyses collapse across
generation.

Increasing similarity along transmission chains could also reflect the
uniform degradation of the signal due to repeated imitation, in which case
acoustic similarity would increase both within as well as between chains. To
test this, we calculated MFCCs for pairs of sounds sampled from within and
between transmission chains across categories, and fit a linear model predicting
acoustic similarity from the generation of sounds. We found that acoustic
similarity increased within chains more than it increased between chains,
`r lm_mod_results(algo_similarity_mod, "edge_generation_n:type_c")` (Fig. S2),
indicating that imitations were stabilizing on divergent acoustic
forms as opposed to converging on similar forms through continuous degradation.

An additional test of stabilization and word-likeness was to measure
whether later generation imitations were transcribed more consistently
than first generation imitations. We collected a total of `r n_transcriptions`
transcriptions --- approximately `r n_transcriptions_per_imitation`
transcriptions per sound. Of these, `r n_english_transcriptions` transcriptions
(8%) were removed because they contained English words. Some examples of the
final transcriptions are presented in Table 1.

```{r table1, results='asis'}
table_caption <- "Examples of words transcribed from imitations."
kable(transcription_examples_small, caption = table_caption)
```

To measure the similarity among transcriptions for a given imitation, we
calculated the average orthographic distance between the most frequent
transcription and all other transcriptions of the same imitation. We then
fit a hierarchical linear model predicting orthographic distance from the
generation of the imitation (First generation, Last generation) with random
effects (intercepts and slopes) for seed sound nested within category. The
results showed that transcriptions of last generation imitations were more
similar to one another than transcriptions of first generation imitations,
`r lmer_mod_results(orthographic_distance_lmertest_mod, "message_c")` (Fig.
S3). The same result is reached through alternative measures of orthographic
distance (Fig. S4). Differences between transcriptions of human vocalizations
and transcriptions directly of environmental sound cues are reported in the
Supplementary Materials (Fig. S6).

## Discussion

Repeating imitations of environmental sounds over generations of imitators
was sufficient to create more word-like forms, even without any explicit
intent to communicate. We defined word-likeness in terms of acoustic stability
and orthographic agreement. With each repetition, the acoustic forms of the
imitations became more similar to one another, indicating they became easier
to repeat with high fidelity. The possibility that this similarity was due to
uniform degradation across all transmission chains was ruled out by algorithmic
analyses of acoustic similarity demonstrating that acoustic similarity increased
within chains but not between them. Additionally, later generation imitations
were transcribed more consistently into English orthography, further supporting
our hypothesis that repeating imitations makes them more stable and word-like.

The results of Experiment 1 demonstrate the ease with which iterated imitation
gives rise to stable word forms. However, the results do not address how these
emergent words relate to the original sounds that were being imitated. As the
imitations became more word-like, were they stabilizing on arbitrary acoustic
and orthographic forms, or did they maintain some resemblance to the
environmental sounds that motivated them? The purpose of Experiment 2 was to
assess the extent to which repeated imitations and their transcriptions
maintained a resemblance to the original set of seed sounds.

# Experiment 2: Resemblance of imitations to original seed sounds

```{r matching, include=FALSE}
```

To assess the resemblance of repeated imitations to the original seed sounds,
we measured the ability of participants naïve to the design of the experiment
to match imitations and their transcriptions back to their original sound
source relative to other seed sounds from either the same category or from
different categories (Fig. 3A). Using these match accuracies, we first asked
whether and for how many generations the imitations and their transcriptions
could be matched back to the original sounds. Second, we asked whether repeated
imitation resulted in a uniform degradation of the signal in each imitation,
or if repeated imitation resulted in some kinds of information degrading more
rapidly than others. Specifically, we tested the hypothesis that if imitations
were becoming more word-like, then they should also be interpreted more
categorically, and thus we anticipated that imitations would lose information
identifying the specific source of an imitation more rapidly than category
information that identifies the category of environmental sound being imitated.

## Methods

### Matching imitations to seed sounds

Participants (_N_=`r n_all_matching_imitations`) recruited from Amazon
Mechanical Turk were paid to listen to imitations, one at a time, and for each
one, choose one of four possible sounds they thought the person was trying to
imitate. The task was not speeded and no feedback was provided. Participants
completed 10 questions at a time.

All imitations were tested in each of the three question types depicted in Fig.
3A. These questions differed in the relationship between the imitation and the
four seed sounds provided as the choices in the question. Question types (True
seed, Category match, Specific match) were assigned between-subject.

### Matching transcriptions to seed sounds

Participants (_N_=`r n_transcription_match_subjs`) recruited from Amazon
Mechanical Turk completed a modified version of the matching survey described
above. Instead of listening to imitations, participants now read a word (a
transcription of an imitation), which they were told was invented to describe
one of the four presented sounds. Of the unique transcriptions that were
generated for each sound (imitations and seed sounds), only the top four most
frequent transcriptions were used in the matching experiment. The distractors
for all questions were between-category, i.e. true seed and category match.
Specific match questions were omitted.

## Results

Response accuracies in matching imitations to seed sounds were fit by a
generalized linear mixed-effects model predicting match accuracy as different
from chance (25%) based on the type of question being answered (True seed,
Category match, Specific match) and the generation of the imitation. Question
types were contrast coded using Category match questions as the baseline
condition in comparison to the other two question types, each containing the
actual seed that generated the imitation as one of the choices. The model
included random intercepts for participant, and random slopes and intercepts for
seed sounds nested within categories.

Accuracy in matching first generation imitations to
seed sounds was above chance for all question types,
`r glmer_mod_results(imitation_matches_overall_mod, "(Intercept)", odds = TRUE)`,
and decreased steadily over generations,
`r glmer_mod_results(imitation_matches_overall_mod, "generation_1")`.
After 8 generations, imitations were still recognizable,
`r glmer_mod_results(imitation_matches_gen8_mod, "(Intercept)", odds = TRUE)`.
We then tested whether this increase in difficulty was constant across
the three types of questions or if some question types became more
difficult than others. The results are shown in Fig. 3B. Performance
decreased over generations more rapidly for specific match questions
that required a within-category distinction than for category match questions
that required a between-category distinction,
`r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_within")`,
suggesting that between-category information was more resistant to loss through
repeated imitation.

An alternative explanation of the drop off in accuracy for specific match
questions but not category match questions is that the within-category
questions are simply more difficult because the sounds presented as choices
are more acoustically similar to one another. However, performance also
decreased relative to the category match questions for the easiest type
of question where the correct answer was the actual seed generating the
imitation (True seed questions; see Fig. 3A). That is, the advantage of having the
true seed among between-category distractors decreased over generations,
`r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_between")`.
The observed decrease in the "true seed advantage" (the advantage of having
the actual seed among the choices) combined with the increase in the "category
advantage" (the advantage of having between-category distractors) shows
that the changes induced by repeated imitation caused the imitations to lose
some of properties that linked the earlier imitations to the specific sound that
motivated them, while nevertheless preserving a more abstract category-based
resemblance.

We next report the results of matching the written transcriptions of the
auditory sounds back to the original environmental sounds. Remarkably,
participants were able to guess the correct meaning of a word that was
transcribed from an imitation that had been repeated up to 8 times,
`r glmer_mod_results(transcription_matches_last_gen_mod, "(Intercept)", odds = TRUE)`
(Fig. 3C). This was true for True seed questions containing
the actual seed generating the transcribed imitation,
`r glmer_mod_results(transcription_matches_last_gen_mod_category, "(Intercept)")`,
and for Category match questions where participants had to associate
transcriptions with a particular category of environmental sounds,
`r glmer_mod_results(transcription_matches_last_gen_mod_exact, "(Intercept)")`.
The effect of generation did not vary across these question types,
`r glmer_mod_results(acc_mod, "question_c:message_c")`. The results of matching
"transcriptions" directly of the environmental sounds are shown in Fig. S6.

```{r fig3, fig.width=8, fig.height=3.5, fig.cap='Repeated imitations retained category resemblance. A. Three types of matching questions. True seed and category match questions had choices from different sound categories. Specific match questions pitted the actual seed against the other seeds within the same category. B. Accuracy in matching vocal imitations to original seed sounds. Curves show predictions of the generalized linear mixed effects models with ±1 SE of the model predictions. C. Accuracy in matching transcriptions of the imitations to original seed sounds (e.g., "boococucuwich" to a water splashing sound). Circles show mean matching accuracy for the vocal imitations that were transcribed for comparison.'}
grid.arrange(
  arrangeGrob(
    read_graphviz("true-seed", "wordsintransition"),
    read_graphviz("category-match", "wordsintransition"),
    read_graphviz("specific-match", "wordsintransition"),
    ncol = 1
  ),
  gg_match_to_seed +
    ggtitle("B"),
  gg_match_transcriptions +
    ggtitle("C") +
    theme(axis.title.y = element_blank()),
  nrow = 1,
  widths = c(0.35, 0.4, 0.25)
)
```

## Discussion

Even after being repeated up to 8 times across 8 different individuals,
vocalizations retained a resemblance to the environmental sound that motivated
them. This resemblance remained even after the vocalizations were transcribed
into orthographic forms. For vocal imitations, but not for transcriptions, this
resemblance was stronger for the category of environmental sound than the specific
seed sound, suggesting that iterated imitation produces vocalizations that are
interpreted by naïve listeners in a more categorical way. Iterated
imitation appears to strip the vocalizations of some of the characteristics that
individuate each particular sound while maintaining some category-based
resemblance. This happens even though participants were never informed about the
meaning of the vocalizations and were not trying to communicate.

Transcriptions of the vocalizations, like the vocalizations themselves, were
able to be matched to the original environmental sounds at levels above chance.
Unlike vocalizations, the transcriptions continued to be matched
more accurately to the true seed compared to the general category. That is,
transcription appears to impact specific and category-level information equally.
One possible explanation of the difference between the acoustic and
orthographic forms of this task is that the process of transcribing a
non-linguistic vocalization into a written word encourages transcribers to
emphasize individuating information about the vocalization. However, this
does not provide a complete explanation of our results: the
fact that transcriptions of imitations can be matched back to other category
members (Category match questions) suggests that transcriptions still do carry
some category information, so this is not a complete explanation of our
results. Another possibility is that by selecting only the most frequent
transcriptions, we unintentionally excluded less frequent transcriptions that
were more diagnostic of category information.

Experiments 1 and 2 document a process of gradual change from an imitation of an
environmental sound to a more word-like form. But do these emergent words
function like other words in a language? In Experiment 3, we test the
suitability of imitations taken from the beginning and end of transmission chains in
serving as category labels in a category learning task.

# Experiment 3: Suitability of created words as category labels

```{r learning, include=FALSE}
```

One consequence of imitations becoming more word-like is that they may make
for better category labels. For example, an imitation from a later generation,
by virtue of having a more word-like form, may be easier to learn as a label
for the category of sounds that motivated it than an earlier imitation, which
is more closely yoked to a particular environmental sound. To the extent
that repeating imitations abstracts away the idiosyncrasies of a particular
category member [@Edmiston:2015he; @Lupyan:2012cp], it may also be easier to
generalize to new category members. We tested these predictions using a category
learning task in which participants learned novel labels for the categories of
environmental sounds. The novel labels were transcriptions of either first or
last generation imitations gathered in Experiment 1.

## Methods

### Selecting words to learn as category labels

Of the `r n_created_words` unique words created through the transmission chain
and transcription procedures, we sampled `r n_lsn_words` words transcribed
from first and last generation imitations that were equated in terms of
length and match accuracy with the original sounds. Our procedure for selecting
otherwise-equal transcriptions is detailed in the Supplementary Materials.

### Procedure

Participants (_N_=`r n_all_lsn_subjs`) were University of Wisconsin
undergraduates who received course credit for participation. Participants
were randomly assigned four novel labels to learn for four categories of
environmental sounds. Full instructions are provided in the Supplementary
Materials. Participants were assigned between-subject to learn labels
(transcriptions) of either first or last generation imitations. On
each trial, participants heard one of the 16 seed sounds. After a 1s delay,
participants saw a label (one of the transcribed imitations) and responded yes
or no using a gamepad controller depending on whether the sound and the word
went together. Participants received accuracy feedback (a bell sound and a green
checkmark if correct; a buzzing sound and a red "X" if incorrect). Four outlier
participants were excluded from the final sample due to high error rates and
slow RTs.

Participants categorized all 16 seed sounds over the course of the experiment,
but they learned them in blocks of 4 sounds at a time. Within each block of 24
trials, participants heard the same four sounds and the same four words multiple
times, with a 50% probability of the sound matching the word on any given trial.
At the start of a new block of trials, participants heard four new sounds they
had not heard before, and had to learn to associate these new sounds with the
words they had learned in the previous blocks.

## Results

Participants began by learning through trial-and-error to associate four
written labels with four categories of environmental sounds. The small
number of categories made this an easy task (mean accuracy after the first
block of 24 trials was 81%; Fig. S5). Participants learning transcriptions
of first or last generation imitations did not differ in overall accuracy,
`r glmer_mod_results(lsn_first_block_error_mod, "message_c", p_value_only = TRUE)`,
or reaction time,
`r lmer_mod_results(lsn_first_block_rt_mod, "message_c", p_value_only = TRUE)`.

After this initial learning phase (i.e. after the first block of trials),
accuracy performance quickly reached ceiling and did not differ between groups
`r glmer_mod_results(lsn_after_first_block_error_mod, "message_c", p_value_only = TRUE)`.
However, the response times of participants learning last
generation transcriptions declined more rapidly with practice
than participants learning first generation transcriptions,
`r lmer_mod_results(lsn_after_first_block_lmertest_mod, "message_c")` (Fig. 4A).
These faster responses suggest that, in addition to becoming more stable both in
terms of acoustic and orthographic properties, repeated imitations become
easier to process as category labels. We predict that given a harder task (i.e.,
more than four categories and 16 exemplars) would yield differences in initial
learning rates as well.

Next, we examined specifically whether transcriptions from last generation imitations
were easier to generalize to novel category exemplars. To test this
hypothesis, we compared RTs on trials immediately prior to the introduction
of novel sounds (new category members) and the first trials after the block
transition (±6 trials). The results revealed a reliable interaction between
the generation of the transcribed imitation and the block transition,
`r lmer_mod_results(transition_lmertest_mod, "block_transition_c:message_c")`
(Fig. 4B). This result suggests that transcriptions from later generation
imitations were easier to generalize to new category members.

```{r fig4, fig.width=6, fig.height=3.5, fig.cap="Repeated imitations made for better category labels. A. Mean RTs for correct responses in the category learning experiment with ±1 SE. B. Cost of generalizing to new category members with ±1 SE."}
grid.arrange(
  rt_plot +
    ggtitle("A"),
  gg_transition +
    theme(axis.title.y = element_blank()) +
    ggtitle("B"),
  nrow = 1,
  widths = c(0.55, 0.45)
)
```

## Discussion

The results of a simple category learning experiment demonstrate a possible
benefit to the way that repeated imitations are molded into more word-like forms.
As a consequence of being more word-like, repeated imitations were responded
to more quickly, and generalized to new category members more easily. These
results suggest an advantage to repeating imitations from the perspective of the
language learner in that they afford better category generalization.

# General Discussion

Accumulating evidence shows that iconic words are prevalent across the spoken
languages of the world [@Dingemanse:2015cu; @Imai:2014dea; @Perniss:2010fb]. And
counter to past assumptions about the limitations of human vocal imitation,
people are surprisingly effective at using vocal imitation to represent and
communicate about the sounds in their environment [@Lemaitre:2016kz] and more
abstract meanings [@Perlman:2015ip]. These findings raise the hypothesis that
early spoken words originated from vocal imitations, perhaps comparable to the
way that many of the signs of signed languages appear to be formed originally
from pantomimes [@Fay:2014ih; @Perlman:2015ip]. Here, we examined whether simply
repeating an imitation of an environmental sound --- with no intention to create a
new word or even to communicate --- produces more word-like forms.

Our results show that through unguided repetition, imitative vocalizations
became more word-like both in form and function. In form, the vocalizations
gradually stabilized over generations, becoming more similar from imitation to
imitation. The standardization was also found when the vocalizations were transcribed
into English orthography. Even as the vocalizations became more word-like, they
maintained a resemblance to the original environmental sounds that motivated
them. Notably, this resemblance appeared more resilient with respect to the
category of sound (e.g., water-splashing sounds), rather than to the specific
exemplar (a particular water-splashing sound). After eight generations the
vocalizations could no longer be matched to the specific sound from which they
originated any more accurately than they could be matched to the general
category of environmental sound. Thus, information that distinguished an
imitation from other sound categories was more resistant to transmission decay
than exemplar information within a category. The resemblance to the
original sounds was maintained even when the vocalizations were transcribed into
a written form: participants were able to match the transcribed vocalizations to
the original sound category at levels above chance.

We further tested the hypothesis that repeated imitation led to vocalizations
becoming more word-like by testing the ease with which people learned the
(transcribed) vocalizations as category labels (e.g., “pshfft” from generation 1
vs. “shewp” from generation 8 as labels for tearing sounds) (Exp. 3). Labels
from the last generation were responded to more quickly than labels from the first
generation. More importantly the labels from the last generation generalized
better to novel category members. This fits with previous research showing that
the relatively arbitrary forms that are typical of words (e.g. “dog”) makes them
better suited to function as category labels compared to direct auditory cues
(e.g., the sound of a dog bark) [@Lupyan:2012cp; @Edmiston:2015he;
@Boutonnet:2015fz].

Compared to the large number of iconic signs in signed languages [e.g.
@GoldinMeadow:2016bw], the number of iconic words in spoken languages may appear
to be very small [@Crystal:1987en; @Newmeyer:1992we]. However, increasing
evidence from disparate language suggests that vocal imitation is, in fact, a
widespread source of vocabulary. Cross-linguistic surveys indicate that
onomatopoeia—iconic words used to represent sounds—are a universal lexical
category found across the world’s languages [@Dingemanse:2012fc]. Even English,
a language that has been characterized as relatively limited in iconic
vocabulary [@Vigliocco:2014fc], is documented as having hundreds of onomatopoeic
words not only for animal and human vocalizations (“meow”, “tweet”, “slurp”,
“babble”, murmur”), but also for a variety of environmental sounds (e.g.,
“ping”, “click”, “plop”) [e.g., @Rhodes:1994au; @Sobkowiak:1990ph]. Besides
words that directly resemble sounds --- the focus of the present study --- many
languages contain semantically broader inventories of ideophones. These words
comprise a grammatically and phonologically distinct class of words that are
used to express various sensory-rich meanings, such as qualities related to
manner of motion, visual properties, textures and touch, inner feelings and
cognitive states [@Dingemanse:2012fc; @Nuckolls:1999ca; @Voeltz:2001vv]. As with
onomatopoeia, ideophones are often recognized by naïve listeners as bearing a
degree of resemblance to their meaning [@Dingemanse:2016vd].

## Limitations

Our study focused on imitations of environmental sounds as a source domain of
meaning. Additional work is required to determine the extent to which vocal
imitation can ground _de novo_ vocabulary in other semantic domains [e.g.,
@Lupyan:2015vic; @Perlman:2015ip]. Our hypothesis that vocal imitation may have
played a role in the origin of some of the first spoken words does not preclude
that gesture played an equal or more important role in establishing the first
linguistic conventions [e.g. @Fay:2013jpa; @GoldinMeadow:2016bw;
@Kendon:2014eg]. In addition, the present studies---like nearly all experimental
investigations of the evolution of language---are limited in their inferential
power due to the use of participants who already speak at least one language. It
may turn out that the ability to repeat vocal imitations and converge on more
word-like forms only arises in humans who already know and use a full linguistic
system, which would limit the relevance of our findings for the origins of
language. Notably, however, our results also suggest an ongoing process by which
new words may become incorporated into the vocabularies of modern languages.

Although our experiment demonstrates that constraints on vocal imitation drive
vocalizations to increase in stability, there are additional factors that are
required in order for vocalizations to be used as words, including experience
with the referents that are being imitated. Here we used familiar sounds that
participants were able to identify without any prior learning. Extending this
research to other domains is likely to reveal the importance of experience with
the referents being imitated in order to establish conventional signs.

# Conclusion

Human language is unique among animal communication systems in, among other
qualities, the extreme diversity of signals in an individual's repertoires (e.g.
words) and how rapidly these signals change over generations of speakers. As a
consequence, the origins of most spoken words are opaque, making it difficult to
investigate the process by which they were formed. Our experimental results show
that the transition from vocal imitation to more word-like signals can, in some
cases, be a rapid and simple process. The mere act of repeated imitation can
drive vocalizations to become more like words in both form and function while
still retaining some resemblance to their real-world referents. These findings
suggest that new words might derive largely from a mechanical process of
repetition, rather than from any deliberate effort to coin a new symbol. It
remains for future work to determine the extent to which this process of word
formation depends on the linguistic competence of modern humans, and whether a
similar process would also characterize repeated imitations by non-linguistic
humans.

# Ethics

This was approved by the University of Wisconsin-Madison's Educational
and Social/Behavioral Sciences Institutional Review Board and conducted in
accordance with the principles expressed in the Declaration of Helsinki.
Informed consent was obtained for all participants.

# Data, code, and materials

Our data along with all methods, materials, and analysis scripts, are available
in public repositories described on the Open Science Framework page for this
research here: [osf.io/3navm](https://osf.io/3navm).

# Competing interests

We have no competing interests.

# Authors' contributions

P.E., M.P., and G.L. designed the research. P.E. conducted the research
and analyzed the data. P.E., M.P., and G.L. wrote the manuscript.

# Funding

This research was supported by NSF 1344279 awarded to G.L.

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
