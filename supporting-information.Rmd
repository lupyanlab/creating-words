---
title: "Creating words from iterated vocal imitation"
bibliography: telephone.bib
output:
  pdf_document:
    citation_package: natbib
    template: templates/pnas-supporting-information.tex
    keep_tex: true
---

```{r config, include=FALSE}
library(knitr)
library(tidyverse)

opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  results="hide",
  fig.path="figs/",
  fig.width=6,
  fig.height=6,
  out.width="7.2cm",  # 8.7 is max
  dpi=144,
  cache=TRUE,
  cache.path=".cache/"
)

# Read all *.R files in the R/ directory in as knitr chunks
list.files("R", "*.R", full.names = TRUE) %>% sapply(read_chunk)
```

```{r 0-setup, include=FALSE}
```

# Selecting seed sounds

```{r 1-selecting-seed-sounds, include=FALSE}
```

Our goal in selecting sounds to serve as seeds in the transmission chains was to
pick multiple sounds within a few different categories such that each category 
member was approximately equally distinguishable from the other sounds within 
the same category. To do this, we started with an initial set of 6 categories 
and 6 sounds in each category and conducted 2 rounds of "odd one out" norming to
reduce the initial set to a final set of 16 seed sounds: 4 sounds in each of 4
categories.

Participants in the odd one out norming procedure listened to the sounds in each
category and picked the one that they thought was **the most different** from
the others. In the first round of norming, participants listened to 6 sounds on
a given trial. We removed the sounds in each category that were the most
different from the others, and repeated the norming process again with 5 sounds
in each category. The resulting sounds that were selected in each category are
considered to be a set of equally distinguishable category members.

```{r 1-odd-one-out-round-1, echo=FALSE, fig.height=10, fig.cap="Results of the first round of seed norming. After collecting these data, two sounds were removed from each category and the norming procedure was conducted again."}
gg_seed_selection_round_1
```

```{r 1-odd-one-out-round-2, echo=FALSE, fig.height=10, fig.cap="Results of the second round of seed norming. After collecting these data, four categories of sounds were selected to use in the main experiment."}
gg_seed_selection_round_2
```

## Final seed sounds

```{r 1-final-seeds, echo=FALSE, results="asis"}
# The audio only works with html obviously but whatever goes between
# the audio tags will be rendered in pdf/word outputs.
player <- '<audio src="%s" controls>%s</audio>'
caption <- "Environmental sounds used as \"seed messages\" in the experiment."

final_seeds %>%
  mutate(
    url = paste0('http://sapir.psych.wisc.edu/telephone/seeds/', filename),
    # A markdown link is required in order to render properly in pdf/word.
    link = sprintf('[%s](%s)', filename, url),
    play = sprintf(player, url, link)
  ) %>%
  select(Category = category, Exemplar = url) %>%
  arrange(Category) %>%
  kable(format = "latex", booktabs = TRUE, caption = caption)
```

# Collecting vocal imitations

```{r 2-collect-imitations-gui, fig.width=3, fig.height=3, fig.cap="The interface for the telephone game. Initially the only action open to players is to hear the message by clicking the top sound icon. After listening to the message once, they could then initiate a recording of their imitation by clicking the bottom sound icon. Turning the recorder off submitted their response, and a new message was loaded."}
img("collect-imitations-gui")
```

# Matching imitations to seeds

```{r 3-match-imitations-gui, fig.width=3, fig.height=3}
img("match-imitations-gui")
```

# Collecting transcriptions of imitations

```{r 4-transcribe-imitations-gui, fig.width=3, fig.height=3}
img("match-imitations-gui")
```

# Matching transcriptions to seeds

```{r 4-match-transcriptions-gui, fig.width=3, fig.height=3}
img("match-imitations-gui")
```

# Learning transcriptions as category labels

To determine which transcriptions to test as category labels, we first selected only those transcriptions which had above chance matching performance when matching back to the original seeds. Then we excluded transcriptions that had less than two unique characters or were over 10 characters long, and sampled from both first and last generation imitations to reach a final set that controlled for overall matching accuracy.

Participants learned, through trial-and-error, the names for four different categories of sounds. On each trial participants listened to one of the 16 environmental sounds used as seeds and then saw a novel word--a transcription of one of the imitations. Participants responded by pressing a green button if the label was the correct label and a red button otherwise. They received accuracy feedback after each trial.

The experiment was divided into blocks so that participants had repeated exposure to each sound and the novel labels multiple times within a block. At the start of a new block, participants received four new sounds from the same four categories (e.g., a new zipping sound, a new water-splash sound, etc.) that they had not heard before, and had to associate these sounds with the same novel labels from the previous blocks. The extent to which their performance declined at the start of each block serves as a measure of how well the label they associated with the sound worked as a label for the category.
