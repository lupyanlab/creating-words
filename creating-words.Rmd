---
title             : "The emergence of words from vocal imitations"
shorttitle        : "Words from imitations"

author:
  - name          : "Pierce Edmiston"
    affiliation   : "1"
    corresponding : yes
    address       : "1202 W. Johnson St., Madison, WI, 53703"
    email         : "pedmiston@wisc.edu"
  - name          : "Marcus Perlman"
    affiliation   : "2"
  - name          : "Gary Lupyan"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Wisconsin-Madison"
  - id            : "2"
    institution   : "Max Planck Institute for Psycholinguistics"

author_note: >
  Pierce Edmiston and Gary Lupyan, Department of Psychology, University of Wisconsin-Madison, Madison, Wisconsin. Marcus Perlman, Max Planck Institute for Psycholinguistics, Nijmegen, Netherlands.
abstract: >
  People have long pondered the origins of language, especially the words that compose them. Here, we report a series of experiments investigating how conventional spoken words might emerge from imitations of environmental sounds. Does the repeated imitation of an environmental sound gradually give rise to novel word forms? In what ways do these words resemble the original sounds that motivated them? Participants played a version of the children’s game “Telephone”. The first generation of participants imitated recognizable environmental sounds (e.g., glass breaking, water splashing). Subsequent generations imitated the imitations for a maximum of 8 generations. The results showed that the imitations became more stable and word-like, and later imitations were easier to learn as category labels. At the same time, even after 8 generations, both spoken imitations and their written transcriptions could be matched above chance to the category of environmental sound that motivated them. These results show how repeated imitation can create progressively more word-like forms while continuing to retain a resemblance to the original sound that motivated them, and speak to the possible role of human vocal imitation in explaining the origins of at least some spoken words.

keywords          : "language evolution, iconicity, vocal imitation, transmission chain"
wordcount         : "5552"

bibliography      : ["telephone.bib"]

figsintext        : yes
figurelist        : yes
tablelist         : yes
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            :
  papaja::apa6_pdf:
    keep_tex: yes
---

```{r config, include=FALSE}
library(knitr)

opts_chunk$set(
  echo=FALSE,
  message=FALSE,
  warning=FALSE,
  results="hide",
  cache=TRUE,
  fig.width=4,
  fig.height=4
)

sapply(list.files("R", "*.R", full.names = TRUE), read_chunk)
```

```{r setup, include=FALSE, cache=FALSE}
```

The importance of imitation and depiction in the origin of signs is clearly observable in signed languages [@Klima:1980si; @GoldinMeadow:2016bw; @Kendon:2014eg], but in considering the idea that imitation in the vocal modality may be key to understanding the origin of spoken words, many have argued that the human capacity for vocal imitation is far too limited to play a significant role [@Arbib:2012htb; @Tomasello:2010or; @Armstrong:2007go; @Corballis:2003ha; @Hockett:1978se; @Hewes:1973vr]. For example, @Pinker:2005cv argued that, “most humans lack the ability… to convincingly reproduce environmental sounds… Thus ‘capacity for vocal imitation’ in humans might be better described as a capacity to learn to produce speech” (p. 209). Consequently, it is still widely assumed that vocal imitation --- or more broadly, the use of any sort of resemblance between form and meaning --- cannot be important to understanding the origin of spoken words. We challenge this view by demonstrating that spoken words can emerge from vocal imitations even without the intention to communicate. We find that repeating vocal imitations of environmental sounds over generations of unique speakers is sufficient to create more word-like vocalizations both in form and function.

Although most words of contemporary spoken languages are not clearly imitative in origin, there has been a growing recognition of the importance of imitative words in spoken languages [@Dingemanse:2015cu; @Perniss:2010fb] and the frequent use of vocal imitation and depiction in spoken discourse [@Clark:1990cl; @Lewis:2009wz]. This has led some to argue for the importance of imitation for understanding the origin of spoken words [e.g., @Brown:1955wy; @Donald:2016kd; @Imai:2014dea; @Perlman:2015ip; @Dingemanse:2014gj]. In addition, counter to previous assumptions, people are highly effective at using vocal imitations to refer to environmental sounds such as coins dropping in a jar or mechanical events such as scraping --- in some cases, even more effective than when using conventional words [@Lemaitre:2014kr]. Recent work has also shown that people are able to create novel imitative vocalizations for more abstract meanings (e.g. ‘slow’, ‘rough’, ‘good’, ‘many’) that are understandable to naïve listeners [@Perlman:2015ip]. These imitations are effective not because people can mimic environmental sounds with high fidelity, but because people are able to produce imitations that capture the salient features of sounds in ways that are understandable to listeners [@Lemaitre:2016kz]. Similarly, the features of onomatopoeic words might highlight distinctive aspects of the sounds they represent. For example, the initial voiced, plosive `/b/` in “boom” represents an abrupt, loud onset, the back vowel `/u/` a low pitch, and the nasalized `/m/` a slow, muffled decay [@Rhodes:1994au].

Thus, converging evidence suggests that people can use vocal imitation as an effective means of communication. But can vocal imitations ever give rise to words that can be integrated into the vocabulary of a language? And if so, by what means might this happen? To answer these questions, we recruited participants to play an online version of the children's game of "Telephone". In the children’s game, a spoken message is whispered from one person to the next. In our version, the original message or "seed sound" was a recording of an environmental sound. The initial group of participants (first generation) imitated these seed sounds, the next generation imitated the previous imitators, and so on for up to 8 generations.

We then conducted a series of analyses and additional experiments to systematically answer the following questions: First, do imitations stabilize in form and become more word-like as they are repeated? Second, do the imitations retain a resemblance to the original environmental sound that inspired them? If so, it should be possible for naïve participants to match the emergent words back to the original seed sounds. Third, do the imitations become more suitable as labels for the category of sounds that motivated them? For example, does the imitation of a particular water-splashing sound become, over generations of repeated imitation, a better label for the more general category of water-splashing sounds?

# Experiment 1: Stabilization of imitations through repetition

```{r stability, include=FALSE}
```

In the first experiment, we collected the vocal imitations, and assessed the extent to which repeating imitations of environmental sounds over generations of unique speakers results in progressive stabilization toward more word-like forms. After collecting the imitations, we measured changes in the stability of the imitations in three ways. First, we measured changes in the perception of acoustic similarity between subsequent generations of imitations along contiguous transmission chains. Second, we used algorithmic measures of acoustic similarity to assess the similarity of imitations sampled within and between transmission chains. Third, we obtained transcriptions of imitations, and measured the extent to which later generation imitations were transcribed with greater consistency and agreement. The results show that repeated imitation results in vocalizations that are easier to repeat with high fidelity and easier to transcribe into English orthography.

## Methods

### Selecting seed sounds

To avoid sounds having lexicalized or conventionalized onomatopoeic forms in English, we used inanimate categories of environmental sounds. Using an odd-one-out norming procedure (_N_=`r n_norming_subjects` participants), an initial set of 36 sounds in 6 categories was reduced to a final set of 16 "seed" sounds: 4 sounds in each of 4 categories. The purpose of this norming procedure was to reach a set of approximately equally distinguishable sounds within each category by systematically removing the sounds that stood out in each category. The results of the norming procedure are shown in Fig. S1. The four final categories were: water, glass, tear, zipper. The final 16 seed sounds can be downloaded from here: [osf.io/n6g7d/download](https://osf.io/n6g7d/download).

### Collecting vocal imitations

Participants (_N_=`r n_imitators`) recruited from Amazon Mechanical Turk were paid to participate in an online version of the children's game of "Telephone". Participants were instructed that they would hear some sound and their task is to reproduce it as accurately as possible using their computer microphone. Full instructions are provided in the Supplemental Materials.

Each participant listened to and imitated four sounds: one from each of the four categories of environmental sounds. Sounds were assigned at random such that participants were unlikely to imitate the same person more than once. Participants were allowed to listen to each target sound multiple times, but were only allowed a single recording in response. Recordings that were too quiet (less than -30 dBFS) were not accepted.

Imitations were monitored by an experimenter to catch any gross errors in recording before they were heard by the next generation of imitators. For example, recordings with loud sounds in the background were removed, and recordings were trimmed to the length of the imitation prior to the next generation. The experimenter also removed sounds that violated the rules of the experiment, e.g., by saying something in English. A total of `r n_removed` (`r n_removed_pct`%) imitations were removed prior to subsequent analysis. The final sample contained `r n_final_imitations` imitations along `r n_branches` contiguous transmission chains (Fig. 1).

```{r fig1, fig.width=4, fig.height=3.5, fig.cap="Vocal imitations collected in the transmission chain experiment. Seed sounds (16) were sampled from four categories of environmental sounds: glass, tear, water, zipper. Participants imitated each seed sound, and then the next generation of participants imitated the imitations, and so on, for up to 8 generations. Chains are unbalanced due to random assignment and the exclusion of some low quality recordings."}
gg_dendrogram
```

### Measuring acoustic similarity

#### Acoustic similarity judgments

Acoustic similarity judgments were gathered from five research assistants who listened to pairs of sounds (approx. 300) and rated their subjective similarity. On each trial, raters heard two sounds from subsequent generations played in random order. They then indicated the similarity between the sounds on a 7-point Likert scale from _Entirely different and would never be confused_ to _Nearly identical_. Raters were encouraged to use as much of the scale as they could while maximizing the likelihood that, if they did this procedure again, they would reach the same judgments. Full instructions are provided in the Supplemental Materials. Inter-rater reliability was calculated as the intra-class coefficient treating the group as the unit of analysis [@irr:2012; @Shrout:1979tg]: `r report_icc_results(irr_results)`. Ratings were normalized for each rater (z-scored) prior to analysis.

#### Algorithmic acoustic similarity

To obtain algorithmic measures of acoustic similarity, we used the acoustic distance functions included in Phonological Corpus Tools [@PCT:1.1]. We computed Mel-frequency cepstral coefficients (MFCCs) between pairs of imitations using 12 coefficients in order to obtain speaker-independent estimates.

### Collecting transcriptions of imitations

Participants (_N_=`r n_transcribers`) recruited from Amazon Mechanical Turk were paid to transcribe vocalizations using English orthography, being instructed to write down what they heard as a single "word" so that the written word would sound as much like the sound as possible. Participants were instructed that this was a word creation task and so to avoid transcribing the vocalizations into existing English words. Each participant completed 10 transcriptions. Transcriptions were gathered for the first and the last three generations of imitations collected in the transmission chain experiment. Participants also provided "transcriptions" of the original environmental seed sounds. Analyses of these transcriptions are reported in the Supplementary Materials (Fig. S5).

To measure similarity among transcriptions of the same imitation, we used the `SequenceMatcher` functions in the `difflib` package of the Python standard library, which implements a version of Ratcliff and Obershelp's "gestalt pattern matching" algorithm. Alternative measures of transcription agreement including exact string matching and the length of the longest substring match were also collected.

### Analyses

Statistical analyses were conducted in R using linear mixed-effects models provided by the `lme4` package [@lme4:2015]. Degrees of freedom and corresponding significance tests for linear mixed-effects models were estimated using the Satterthwaite approximation via the `lmerTest` package [@lmerTest:2016]. Random effects (intercepts and slopes) for subjects and for items were included wherever appropriate, and are described below.

### Data availability

Our data along with all methods, materials, and analysis scripts, are available in public repositories described on the Open Science Framework page for this research here: [osf.io/3navm](https://osf.io/3navm).

## Results

### Acoustic similarity increased through iteration

Imitations of environmental sounds became more stable over the course of being repeated as revealed by increasing acoustic similarity judgments along individual transmission chains. Acoustic similarity ratings were fit with a linear mixed-effects model predicting perceived acoustic similarity from generation with random effects (intercepts and slopes) for raters. To test whether the hypothesized increase in acoustic simliarity was true across all seed sounds and categories, we added random effects (intercepts and slopes) for seed sounds nested within categories. The results showed that, across raters and seeds, imitations from later generations were rated as sounding more similar to one another than imitations from earlier generations, `r lmer_mod_results(similarity_judgments_lmertest_mod, "edge_generation_n")` (Fig. 2). This result suggests that imitations became more stable (i.e., easier to imitate with high fidelity) with each generation of repetition.

```{r fig2, fig.cap="Change in perception of acoustic similarity over generations of iterated imitation. Points depict mean acoustic similarity ratings for pairs of imitations in each category. The predictions of the linear mixed-effects model are shown with ±1 SE. Acoustic similarity increased over generations, indicating that repetition made the vocalizations easier to imitate with high fidelity."}
gg_similarity_judgments
```

### Acoustic similarity was highest within transmission chains

Increasing similarity along transmission chains could also reflect the continuous degradation of the signal due to repeated imitation, in which case we would expect acoustic similarity to increase both within as well as between transmission chains as a function of generation of imitation. To rule out this alternative explanation, we calculated MFCCs for pairs of sounds sampled from within and between different transmission chains from consecutive generations across categories. To analyze the results, we fit a linear model predicting normalized acoustic similarity scores (z-scores) from the generation of sounds. A hierarchical model was not appropriate for this analysis because the between-chain pairs of sounds were sampled from different categories, preventing any random effects due to category or seed from being included in the model. We found that acoustic similarity increased within chains more than it increased between chains, `r lm_mod_results(algo_similarity_mod, "edge_generation_n:type_c")` (Fig. S2). This result supports the conclusion that transmission chains were stabilizing on divergent acoustic forms as opposed to all chains converging on similar forms through continuous degradation.

### Later generation imitations were transcribed more consistently

An additional test of stabilization and word-likeness was to measure whether later generation imitations were transcribed more consistently than first generation imitations. We collected a total of `r n_transcriptions` transcriptions --- approximately `r n_transcriptions_per_imitation` transcriptions per sound. Of these, `r n_english_transcriptions` transcriptions (8%) were removed because they contained English words. Some examples of the final transcriptions are presented in Table 1.

```{r table1, results='asis'}
table_caption <- "Examples of words transcribed from imitations."
kable(transcription_examples, caption = table_caption)
```

To measure the similarity among transcriptions, we calculated the orthographic distance between the most frequent transcription and all other transcriptions of a given imitation. The orthographic distance measure was a ratio based on longest contiguous matching subsequences between pairs of transcriptions. We then fit a hierarchical linear model predicting orthographic distance from the generation of the imitation (First generation, Last generation) with random effects (intercepts and slopes) for seed sound nested within category[^df]. The results showed that transcriptions of last generation imitations were more similar to one another than transcriptions of first generation imitations, `r lmer_mod_results(orthographic_distance_lmertest_mod, "message_c")` (Fig. 3). The same result is reached through alternative measures of orthographic distance, such as the percentage of exact transcription matches for each imitation, `r lm_mod_results(exact_string_matches_mod, "message_c")`, and the length of the longest matching substring, `r lmer_mod_results(substr_length_mod, "message_c")` (Fig. S3). Differences between transcriptions of human vocalizations and transcriptions directly of environmental sounds are presented in the Supplementary Materials (Fig. S5).

[^df]: Random effects for subject were not appropriate because the distance measure was derived from pairwise comparisons of transcriptions generated by different transcribers. As a result, the degrees of freedom for the significance tests for the parameters of this model reflect the Satterthwaite approximation based on the number of seed sounds (16) nested within categories (4), not the number of unique transcribers (_N_=`r n_transcribers`).

```{r fig3, fig.cap="Orthographic agreement among transcriptions of first and last generation imitations. Points depict the mean orthographic distance between the most frequent transcription and all other transcriptions of a given imitation, with error bars denoting ±1 SE of the hierarchical linear model predictions. Transcriptions of later generation imitations were more similar to one another than transcriptions of first generation imitations, suggesting that repeating imitations made them easier to transcribe into English orthography than direct imitations of environmental sounds."}
gg_distance
```

## Discussion

Repeating imitations of environmental sounds over generations of unique speakers was sufficient to create more wordlike forms even without any instruction to do so. We defined wordlike-ness in terms of acoustic stability and orthographic agreement. With additional repetitions, the acoustic forms of the imitations became more similar to one another, indicating they became easier to repeat with high fidelity. The possibility that this similarity was due to uniform degradation across all transmission chains was ruled out by algorithmic analyses of acoustic similarity within and between chains demonstrating that acoustic similarity increased within chains but not between them. Additionally, later generation imitations were transcribed more consistently into English orthography, further supporting our hypothesis that repeating imitations makes them more word-like.

The results of Experiment 1 demonstrate the ease with which iterated imitation gives rise to unique word forms. However, the results do not address how these emergent words relate to the original sounds that were being imitated. As the imitations became more word-like, were they stabilizing on arbitrary acoustic and orthographic forms, or did they maintain some resemblance to the environmental sounds that motivated them? The purpose of Experiment 2 was to assess the extent to which repeated imitations and their transcriptions maintained a resemblance to the original set of seed sounds.

# Experiment 2: Resemblance of imitations to original seed sounds

```{r matching, include=FALSE}
```

To assess the resemblance of repeated imitations to the original seed sounds, we measured the ability of participants naïve to the design of the experiment to match imitations and their transcriptions back to their original sound source relative to other seed sounds from either the same category or from different categories (Fig. 4). We used match accuracies to answer two questions concerning the effect of iterated imitation on resemblance to the original seed sounds. First, we asked whether and for how many generations the imitations and their transcriptions could be matched back to the original sounds. Second, we asked whether repeated imitation resulted in a uniform degradation of the signal in each imitation, or if repeated imitation resulted in some kinds of information degrading more rapidly than others. Specifically, we tested the hypothesis that if imitations were becoming more word-like, then they should also be interpreted more categorically, and thus we predicted that the imitations might lose individuating information that identifies the specific source of an imitation more rapidly than category information that identifies the general category of environmental sound being imitated.

```{r fig4, fig.width=4, fig.height=3.5, fig.cap="Three types of matching questions used to assess the resemblance between the imitation (and transcriptions of imitations) and the original seed sounds. For each question, participants listened an imitation (dashed circles) or read a transcription of one, and had to guess which of 4 sound choices (solid circles) they thought the person was trying to indicate. True seed questions contained the specific sound that generated the imitation as one of the choices (the correct response). The remaining sound choices were sampled from different categories. Category match questions replaced the original seed sound with another sound from the same category. Specific match questions pitted the actual seed against the other seeds within the same category."}
grid.arrange(
  read_graphviz("true-seed", "wordsintransition"),
  read_graphviz("category-match", "wordsintransition"),
  read_graphviz("specific-match", "wordsintransition"),
  ncol = 1
)
```

## Methods

### Matching imitations to seed sounds

Participants (_N_=`r n_all_matching_imitations`) recruited from Amazon Mechanical Turk were paid to listen to imitations, one at a time, and for each one, choose one of four possible sounds they thought the person was trying to imitate. The task was unspeeded and no feedback was provided. Participants completed 10 questions at a time.

All 365 imitations were tested in each of the three question types depicted in Fig. 4. These questions differed in the relationship between the imitation and the four seed sounds provided as the choices in the question. Question types (True seed, Category match, Specific match) were assigned between-subject. Participants in the True seed and Category match conditions were provided four seed sounds from different categories as choices in each question. Participants in the Specific match condition were provided four seed sounds from the same category.

### Matching transcriptions to seed sounds

Participants (_N_=`r n_all_transcription_match_subjs`) recruited from Amazon Mechanical Turk completed a modified version of the matching survey described above. Instead of listening to imitations, participants now read a word (a transcription of an imitation), which they were told was an invented word. They were instructed that the word was invented to describe one of the four presented sounds, and they had to guess which one. The distractors for all questions were between-category, i.e. true seed and category match. Specific match questions were omitted.

Of the unique transcriptions that were generated for each sound (imitations and seed sounds), only the top four most frequent transcriptions were used in the matching experiment. Participants who failed a catch trial (_N_=`r n_transcription_match_subjs_failed_catch_trial`) were excluded, leaving `r n_transcription_match_subjs` participants in the final sample.

## Results

### Imitations retained category information more than individuating information

Response accuracies in matching imitations to seed sounds were fit by a generalized linear mixed-effects model predicting match accuracy as different from chance (25%) based on the type of question being answered (True seed, Category match, Specific match) and the generation of the imitation. Question types were contrast coded using Category match questions as the baseline condition in comparison to the other two question types each containing the actual seed that generated the imitation as one of the choices. The model included random intercepts for participant[^generations], and random slopes and intercepts for seed sounds nested within categories.

[^generations]: Random slopes for generation were not appropriate in the by-subject random effects because data collection was batched by generation of imitation, and therefore each participant did not sample across the range of generations.

Accuracy in matching imitations to seed sounds was above chance for all question types for the first generation of imitations, `r glmer_mod_results(imitation_matches_overall_mod, "(Intercept)", odds = TRUE)`, and decreased steadily over generations, `r glmer_mod_results(imitation_matches_overall_mod, "generation_1")`. We then tested whether this increase in difficulty was constant across the three types of questions or if some question types became more difficult than others. The results are shown in Fig. 5A. Performance decreased over generations more rapidly for questions requiring a within-category distinction than for between-category questions, `r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_within")`, suggesting that between-category information was more resistant to loss through repeated imitation.

An alternative explanation for this result is that the within-category match questions are simply more difficult because the sounds provided as choices are more acoustically similar to one another than the between-category questions, and therefore, performance might be expected to drop off more rapidly with repeated imitation for these more difficult questions[^below]. However, performance also decreased for the easiest type of question where the correct answer was the actual seed generating the imitation (True seed questions; see Fig. 4); the advantage of having the true seed among between-category distractors decreased over generations, `r glmer_mod_results(imitation_matches_mod, "generation_1:same_v_between")`. The observed increase in the "category advantage" (i.e., the advantage of having between-category distractors) combined with a decrease in the "true seed advantage" (the advantage of having the actual seed among the choices), shows that the changes induced by repeated imitation caused the imitations to lose some of properties that linked the earlier imitations to the specific sound that motivated them, while nevertheless preserving a more abstract category-based resemblance.

[^below]: We observed that performance on some Specific match questions dropped below chance for later generations indicating participants had an apparent aversion to the nominally correct answer. Additional analyses showed that participants were not converging on a single incorrect response. The reason for this pattern is at present unclear. Removing these trials from the analysis does not substantively change the conclusions.

### Transcriptions retained information about seed sources

We next report the results of matching the written transcriptions of the auditory sounds back to the original environmental sounds. Remarkably, participants were able to guess the correct meaning of a word that was transcribed from an imitation that had been repeated up to 8 times, `r glmer_mod_results(transcription_matches_last_gen_mod, "(Intercept)", odds = TRUE)` (Fig. 5B). This was true for True seed questions containing the actual seed generating the transcribed imitation, `r glmer_mod_results(transcription_matches_last_gen_mod_category, "(Intercept)")`, and for Category match questions where participants had to associate transcriptions with a particular category of environmental sounds, `r glmer_mod_results(transcription_matches_last_gen_mod_exact, "(Intercept)")`. The effect of generation did not vary across these question types, `r glmer_mod_results(acc_mod, "question_c:message_c")`. The results of matching "transcriptions" directly of the environmental sounds are shown in Fig. S5.

```{r fig5, fig.width=6, fig.height=3.5, fig.cap='Repeated imitations retained category resemblance. A. Accuracy of matching vocal imitations to original seed sounds as a function of the generation during which the imitation was produced. Curves show predictions of the generalized linear mixed effects models with ±1 SE of the model predictions. The "category advantage" (Category match vs. Specific match) increased over generations, while the "true seed advantage" (True seed v. Category match) decreased (see main text), suggesting that imitations lose within-category information more rapidly than between-category information. B. Accuracy of matching transcriptions of the imitations to original seed sounds (e.g., "boococucuwich" to a water splashing sound). Transcriptions of imitations could still be matched back to the category of sound that motivated the original imitation even after 8 generations. Circles show mean matching accuracy for the corresponding vocal imitations for comparison.'}
grid.arrange(
  gg_match_to_seed +
    ggtitle("A"),
  gg_match_transcriptions +
    ggtitle("B") +
    theme(axis.title.y = element_blank()),
  nrow = 1,
  widths = c(0.6, 0.4)
)
```

## Discussion

Even after being repeated up to 8 times, imitations retained a resemblance to the environmental sound that motivated them, even after being transcribed into orthographic forms. For imitations, but not for transcriptions, this resemblance was stronger for the category of environmental sound than the actual seed sound, suggesting that through repetition, the imitations were becoming more categorical. This result supports the results of Experiment 1 in demonstrating another aspect of wordlike-ness achieved through repeated imitation: Words, in addition to being stable in acoustic and orthographic forms, are also categorical, denoting all members of a category equally as opposed to identifying individual category members. Repeating imitations of environmental sounds is sufficient to remove some of the individuating characteristics of the imitation while retaining a category-based resemblance.

The reason the same effect was not observed in matching accuracy for transcriptions is unknown. One possible reason is that the process of transcribing a non-linguistic vocalization into a written word encourages transcribers to emphasize individuating information about the vocalization. However, the fact that transcriptions of imitations can be matched back to other category members (Category match questions) suggests that transcriptions are still carrying some category information. Another possible reason is that by subsetting the most frequent transcriptions, we unintentionally excluded less frequent transcriptions that were more diagnostic of category information.

Experiments 1 and 2 document a process of gradual change from an imitation of an environmental sound to a more wordlike form. But do these emergent words function like other words in the language? In Experiment 3, we test the suitability of words taken from the beginning and end of transmission chains in serving as category labels in a category learning task.

# Experiment 3: Suitability of created words as category labels

```{r learning, include=FALSE}
```

One consequence of imitations becoming more word-like is that they may make for better category labels. For example, an imitation from a later generation, by virtue of having a more word-like form, may be easier to learn as a label for the category of sounds that motivated it than an earlier imitation, which is more closely yoked to a particular environmental sound. To the extent that repeating imitations abstracts away the idiosyncrasies of a particular category member [@Edmiston:2015he; @Lupyan:2012cp], it may also be easier to generalize to new category members. We tested these predictions using a category learning task in which participants learned novel labels as category labels of the seed environmental sounds. The novel labels were transcriptions of either first or last generation imitations gathered in Experiment 1.

## Methods

### Selecting words to learn as category labels

Our transmission chain design and subsequent transcription procedure created `r n_created_words` unique words. From these, we sampled words transcribed from first and last generation imitations, as well as transcriptions of the original seed sounds. Our procedure for sampling transcriptions to use as category labels was as follows: First, we removed transcriptions that contained less than 3 unique characters and transcriptions that were over 10 characters long. Of the remaining transcriptions, a sample of `r n_lsn_words` were selected that were approximately equally associated with the target category. To measure the association between each imitation and its target category (the category of the seed sound), we used the match accuracy scores reported in Experiment 2. The reason for using this measure of association strength as a control for selecting words to learn as category labels was to be able to select words that were initially equally associated with the target categories. Equating along this dimension allowed for a more focused test of differences between the words in terms of generalization to new category members. The final sample of transcriptions were selected using a bootstrapping procedure which involved selecting a desired mean (the average association strength for eligible transcriptions of last generation imitations) and sampling transcriptions from first generation imitations and from seed sounds until the match accuracy of those imitations matched the desired mean within 1 standard deviation.

### Procedure

Participants (_N_=`r n_all_lsn_subjs`) were University of Wisconsin undergraduates who received course credit for participation. Participants were randomly assigned four novel labels to learn for four categories of environmental sounds. Full instructions are provided in the Supplementary Materials. Participants were assigned between-subject to learn labels (transcriptions) of either first or last generation imitations. Some participants learned labels from transcriptions of seed sounds (Fig. S6). On each trial, participants heard one of the 16 seed sounds. After a 1s delay, participants saw a label (one of the transcribed imitations) and responded yes or no using a gamepad controller depending on whether the sound and the word went together. Participants received accuracy feedback (a bell sound and a green checkmark if correct; a buzzing sound and a red "X" if incorrect). Four outlier participants were excluded from the final sample due to high error rates and slow RTs.

Participants categorized all 16 seed sounds over the course of the experiment, but they learned them in blocks of 4 sounds at a time. Within each block of 24 trials, participants heard the same four sounds and the same four words multiple times, with a 50% probability of the sound matching the word on any given trial. At the start of a new block of trials, participants heard four new sounds they had not heard before, and had to learn to associate these new sounds with the words they had learned in the previous blocks.

## Results

### Later generation transcriptions yielded more efficient responding

Participants began by learning through trial-and-error to associate four written labels with four categories of environmental sounds. The small number of categories made this an easy task (mean accuracy after the first block of 24 trials was 81%; Fig. S4). Participants learning transcriptions of first or last generation imitations did not differ in overall accuracy, `r glmer_mod_results(lsn_first_block_error_mod, "message_c", p_value_only = TRUE)`, or reaction time, `r lmer_mod_results(lsn_first_block_rt_mod, "message_c", p_value_only = TRUE)`. After this initial learning phase (i.e. after the first block of trials), accuracy performance quickly reached ceiling and did not differ between groups `r glmer_mod_results(lsn_after_first_block_error_mod, "message_c", p_value_only = TRUE)`. However, the response times of participants learning last generation transcriptions declined more rapidly with practice than participants learning first generation transcriptions, `r lmer_mod_results(lsn_after_first_block_lmertest_mod, "message_c")` (Fig. 6A). These faster responses suggest that, in addition to becoming more stable both in terms of acoustic and orthographic properties, repeating imitations makes them easier to process as category labels. We predict that given a harder task (i.e., more than four categories and 16 exemplars) would yield differences in initial learning rates as well.

### Later generation transcriptions were better generalized

Next, we examined whether transcriptions from last generation imitations were easier to generalize to novel category exemplars. To test this hypothesis, we compared RTs on trials immediately prior to the introduction of novel sounds (new category members) and the first trials after the block transition (±6 trials). The results revealed a reliable interaction between the generation of the transcribed imitation and the block transition, `r lmer_mod_results(transition_lmertest_mod, "block_transition_c:message_c")` (Fig. 6B). This result suggests that transcriptions from later generation imitations were easier to generalize to new category members.

```{r fig6, fig.width=6, fig.height=3.5, fig.cap="Repeated imitations made for better category labels. Participants learned novel labels (transcriptions of first or last generation imitations) for categories of environmental sounds. A. Mean RTs for correct responses in the category learning experiment with ±1 SE. Participants achieved faster RTs in matching transcribed labels to environmental sounds for labels transcribed from later compared to earlier generation imitations. B. Cost of generalizing to new category members with ±1 SE. After each block of trials, new environmental sounds were introduced, requiring participants to generalize the previously learned category labels to new category members. There was a generalization cost for the first generation labels, but not the last generation labels."}
grid.arrange(
  rt_plot +
    ggtitle("B"),
  gg_transition +
    theme(axis.title.y = element_blank()) +
    ggtitle("B"),
  nrow = 1,
  widths = c(0.55, 0.45)
)
```

## Discussion

The results of a simple category learning experiment demonstrate a possible benefit to the stabilization of repeated imitations on more wordlike forms. As a consequence of being more wordlike, repeated imitations were responded to more quickly, and generalized to new category members more easily. These results suggest an advantage to repeating imitations from the perspective of the language learner in that they afford better category generalization.

# General Discussion

Imitative words are found across the spoken languages of the world [@Dingemanse:2015cu; @Imai:2014dea; @Perniss:2010fb]. Counter to past assumptions about the limitations of human vocal imitation, people are surprisingly effective at using vocal imitation to represent and communicate about the sounds in their environment [@Lemaitre:2016kz] and more abstract meanings [@Perlman:2015ip], making the hypothesis that early spoken words originated from imitations a plausible one. We examined whether simply repeating an imitation of an environmental sound---with no intention to create a new word or even to communicate---produces more word-like forms.

Our results show that through simple repetition, imitative vocalizations became more word-like both in form and function. In form, the vocalizations gradually stabilized over generations, becoming more similar from imitation to imitation. They also became increasingly standardized in accordance with English orthography, as later generations were more consistently transcribed into English words, providing converging evidence of stabilization. In function, the increasingly word-like forms became more effective as category labels. In a category learning experiment, naïve participants were faster at matching category labels derived from later-generation imitations than those derived directly from imitations of environmental sounds. This fits with previous research showing that the relatively arbitrary forms that are typical of words (e.g. “dog”) makes them better suited to function as category labels compared to direct auditory cues [e.g. the sound of a dog bark; @Lupyan:2012cp; @Edmiston:2015he; @Boutonnet:2015fz].

Even as the vocalizations became more word-like, they nevertheless maintained an imitative quality. After eight generations they could no longer be matched to the particular sound from which they originated any more accurately than they could be matched to the general category of environmental sound. Thus, information that distinguished an imitation from other sound categories was more resilient to transmission decay than exemplar information within a category. Remarkably, even after the vocalizations were transcribed into English orthography, participants were able to guess their original sound category from the written "words". In contrast to the vocalizations, participants continued to be more accurate at matching late generation transcriptions back to their particular source sound relative to other exemplars from the same category.

Although the number of imitative words in contemporary languages may appear to be very small [@Crystal:1987en; @Newmeyer:1992we], increasing evidence from disparate languages shows that vocal imitation is, in fact, a widespread source of vocabulary. Cross-linguistic surveys indicate that onomatopoeia---imitative words used to represent sounds---are a universal lexical category found across the world's languages [@Dingemanse:2012fc]. Even English, a language that has been characterized as relatively limited in iconic vocabulary [@Vigliocco:2014fc], is documented as having hundreds of clearly imitative words including words for human and animal vocalizations as well as various types of environmental sounds [@Rhodes:1994au; @Sobkowiak:1990ph]. Besides words that are directly imitative of sounds---the focus of the present study --- many languages contain semantically broader inventories of ideophones. These words comprise a grammatically and phonologically distinct class of words that are used to express various sensory-rich meanings, such as qualities related to manner of motion, visual properties, textures and touch, inner feelings and cognitive states [@Dingemanse:2012fc; @Nuckolls:1999ca; @Voeltz:2001vv]. As with onomatopoeia, ideophones are often recognized by naïve speakers as bearing a degree of resemblance to their meaning [@Dingemanse:2016vd].

Our study focused on imitations of environmental sounds and more work remains to be done to determine the extent to which vocal imitation can ground de novo vocabulary creation in other semantic domains [e.g., @Perlman:2015ip; @Lupyan:2015vic]. What the present results make clear is that the transition from imitation to word can be a rapid and simple process: the mere act of iterated imitation can drive vocalizations to become more word-like in both form and function. Notably, just as onomatopoeia and ideophones of natural languages maintain a resemblance to the quality they represent, the present vocal imitations transitioned to words while retaining a resemblance to the original sound that motivated them.

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
